# Системное проектирование, устранение неполадок и производительность

## Содержание

- [Системное проектирование](#системное-проектирование)
  - [Введение в системное проектирование](#введение)
  - [Проектирование крупных систем](#проектирование-крупных-систем)
  - [Масштабирование](#масштабирование)
  - [Масштабирование за пределами центра обработки данных](#масштабирование-за-пределами-центра-обработки-данных)
  - [Шаблоны проектирования для отказоустойчивости](#шаблоны-проектирования-для-отказоустойчивости)
  - [Заключение](#заключение)

- [Сетевые технологии](#сетевые-технологии)
  - [Введение в сетевые технологии](#введение-1)
  - [Безопасность](#безопасность)
  - [Масштабирование](#масштабирование-1)
  - [Время отклика (RTT)](#время-отклика-rtt)
  - [Особенности инфраструктуры](#особенности-инфраструктуры)
  - [Заключение](#заключение-1)

- [Контейнеризация и оркестрация](#контейнеризация-и-оркестрация)
  - [Введение в контейнеры](#введение-2)
  - [Что такое контейнеры](#что-такое-контейнеры)
  - [Почему контейнеры](#почему-контейнеры)
  - [Разница между виртуальными машинами и контейнерами](#разница-между-виртуальными-машинами-и-контейнерами)
  - [Как реализованы контейнеры](#как-реализованы-контейнеры)
  - [Пространства имен](#пространства-имен)
  - [Cgroups](#cgroups)
  - [Контейнерные движки](#контейнерные-движки)
  - [Контейнеризация с Docker](#контейнеризация-с-docker)
  - [Оркестрация с Kubernetes](#оркестрация-с-kubernetes)
  - [Заключение](#заключение-2)

- [Непрерывная интеграция и непрерывная доставка](#непрерывная-интеграция-и-непрерывная-доставка)
  - [Введение](#введение-3)
  - [Что такое CI/CD](#что-такое-cicd)
  - [Краткая история CI/CD и DevOps](#краткая-история-cicd-и-devops)
  - [Непрерывная интеграция](#непрерывная-интеграция)
  - [Непрерывная доставка и развертывание](#непрерывная-доставка-и-развертывание)
  - [CI/CD конвейер на основе Jenkins](#cicd-конвейер-на-основе-jenkins)
  - [Заключение](#заключение-3)

- [Linux: промежуточный уровень](#linux-промежуточный-уровень)
  - [Введение](#введение-4)
  - [Управление пакетами](#управление-пакетами)
  - [Устройства хранения](#устройства-хранения)
  - [Архивирование и резервное копирование](#архивирование-и-резервное-копирование)
  - [Введение в Vim](#введение-в-vim)
  - [Bash-скриптинг](#bash-скриптинг)
  - [Заключение](#заключение-4)

- [Системные вызовы и сигналы](#системные-вызовы-и-сигналы)
  - [Введение](#введение-5)
  - [Введение в прерывания и сигналы](#введение-в-прерывания-и-сигналы)
  - [Типы сигналов](#типы-сигналов)
  - [Отправка сигналов процессу](#отправка-сигналов-процессу)
  - [Обработка сигналов](#обработка-сигналов)
  - [Роль сигналов в системных вызовах на примере wait()](#роль-сигналов-в-системных-вызовах-на-примере-wait)
  - [Введение в системные вызовы](#введение-в-системные-вызовы)
  - [Типы системных вызовов](#типы-системных-вызовов)
  - [Пользовательский режим, режим ядра и их переходы](#пользовательский-режим-режим-ядра-и-их-переходы)
  - [Работа системного вызова write()](#работа-системного-вызова-write)
  - [Отладка в Linux с помощью strace](#отладка-в-linux-с-помощью-strace)
  - [Заключение](#заключение-5)

- [Устранение неполадок и повышение производительности системы](#устранение-неполадок-и-повышение-производительности-системы)
  - [Введение](#введение-6)
  - [Устранение неполадок](#устранение-неполадок)
  - [Важные инструменты](#важные-инструменты)
  - [Повышение производительности](#повышение-производительности)
  - [Пример устранения неполадок](#пример-устранения-неполадок---утечка-памяти)
  - [Заключение](#заключение-6)

## Системное проектирование

### Введение

Мы говорили о создании базового приложения для обмена фотографиями в предыдущей фазе этого курса. Наши основные требования к приложению заключались в том, что:

1. Оно должно работать для достаточно большого числа пользователей
2. Избегать сбоев сервиса/кластера в случае возникновения проблем

Другими словами, мы хотели создать систему, которая была бы доступной, масштабируемой и отказоустойчивой. Мы продолжим проектирование этого приложения и рассмотрим дополнительные концепции в ходе этого процесса.

Приложение для обмена фотографиями - это веб-приложение, которое будет обрабатывать все: от регистрации пользователя, входа в систему, загрузки, генерации ленты, взаимодействия пользователей и взаимодействия с загруженным контентом. Также база данных для хранения этой информации. В самом простом дизайне и веб-приложение, и база данных могут работать на одном сервере.

Основываясь на этом, мы поговорим об элементах производительности в системном проектировании - установке правильных метрик измерения производительности и использовании их для принятия решений по проектированию, повышении производительности с использованием кэширования, сетей доставки контента (CDN) и т.д. Мы также поговорим о том, как проектировать для обеспечения устойчивости, рассматривая некоторые шаблоны системного проектирования - плавную деградацию, тайм-ауты и прерыватели цепи.

### Проектирование крупных систем

Проектирование системы обычно начинается с абстрактного уровня - у нас есть большие функциональные блоки, которые должны работать вместе и абстрагированы в слои фронтенда, бэкенда и базы данных. Однако, когда приходит время реализовать систему, особенно в качестве SRE, у нас нет другого выбора, кроме как мыслить конкретными терминами. Серверы имеют фиксированный объем памяти, емкость хранилища и вычислительную мощность. Поэтому нам нужно думать о реалистичных ожиданиях от нашей системы, оценивать требования, переводить их в конкретные требования для каждого компонента системы, такого как сеть, хранилище и вычисления. Именно так обычно строятся почти все крупномасштабные системы.

### Масштабирование

Учитывая огромный объем трафика, который может генерироваться нашим приложением, и связанные с этим требования к ресурсам с точки зрения памяти и ЦП, давайте разделим приложение на более мелкие части. Один из самых простых способов сделать это - просто разделить приложение по конечным точкам и запустить их как отдельные экземпляры.

Изображения могут храниться в объектном хранилище, которое может масштабироваться независимо, а не размещаться на серверах, где находится приложение или база данных. Это уменьшит требования к ресурсам для серверов.

#### Кэширование

Кэш используется для временного хранения данных, к которым, вероятно, будет осуществляться повторный доступ, часто повторяющийся. Когда запрашиваемые данные находятся в кэше, это называется "попаданием в кэш". "Промах кэша" - очевидное дополнение. Хорошо расположенный кэш может значительно сократить время отклика на запрос, а также улучшить масштабируемость системы. Кэши могут быть размещены на нескольких уровнях между пользователем и приложением.

### Масштабирование за пределами центра обработки данных

#### Кэширование статических ресурсов

Расширяя существующее решение кэширования, мы приходим к сетям доставки контента (CDN). CDN - это слой кэширования, который находится ближе всего к пользователю. Значительная часть ресурсов, обслуживаемых на веб-странице, может не меняться ежечасно или даже ежедневно. В таких случаях мы хотели бы кэшировать их на уровне CDN, уменьшая нашу нагрузку. CDN не только помогают уменьшить нагрузку на наши серверы, снимая бремя обслуживания статических/требующих большой пропускной способности ресурсов, но и позволяют нам быть ближе к нашим пользователям благодаря точкам присутствия (POP). CDN также позволяют нам выполнять гео-балансировку нагрузки, в случае если у нас есть несколько центров обработки данных по всему миру, и мы хотели бы обслуживать из ближайшего возможного центра обработки данных (DC).

#### Точки присутствия

CDN POP - это географически распределенные центры обработки данных, направленные на то, чтобы быть ближе к пользователям. POP уменьшают время прохождения, доставляя контент из места, ближайшего к пользователю. POP обычно могут не иметь всего контента, но имеют кэширующие серверы, которые кэшируют статические ресурсы и получают остальной контент с сервера происхождения, где фактически находится приложение. Их основная функция - уменьшить время прохождения, приближая контент к посетителю веб-сайта. POP также могут направлять трафик в один из нескольких возможных исходных DC. Таким образом, POP могут быть использованы для добавления устойчивости, а также балансировки нагрузки.

### Шаблоны проектирования для отказоустойчивости

Устойчивая система - это система, которая может продолжать функционировать перед лицом невзгод. С нашим приложением могут возникнуть многочисленные сбои, которые действуют как невзгоды. Могут быть сбои на уровне сети, которые выводят из строя целые центры обработки данных, могут быть проблемы на уровне стойки или на уровне сервера, или может быть что-то не так с облачным провайдером. Мы также можем исчерпать емкость, или может быть неправильный код, который ломает систему. Мы поговорим о паре таких проблем и поймем, как мы можем спроектировать систему для обхода таких вещей. В некоторых случаях обходной путь может быть невозможен. Однако все равно ценно знать потенциальные уязвимости для стабильности системы.

Устойчивые архитектуры используют такие шаблоны системного проектирования, как плавная деградация, квоты, тайм-ауты и прерыватели цепи. Давайте рассмотрим некоторые из них в этом разделе.

#### Квоты

Система может иметь компонент или конечную точку, которая потребляется несколькими компонентами и конечными точками. Важно иметь что-то на месте, что предотвратит перегрузку такой системы одним потребителем или клиентом. Квоты - один из способов сделать это - мы просто назначаем определенную квоту для каждого компонента - путем указания запросов за единицу времени. Любой, кто нарушает квоту, либо предупреждается, либо отбрасывается, в зависимости от реализации. Таким образом, одна из наших собственных систем, работающая неправильно, не может привести к отказу в обслуживании для других. Квоты также помогают нам предотвратить каскадные сбои.

#### Плавная деградация

Когда система с несколькими зависимостями сталкивается с отказом в одной из зависимостей, плавная деградация до минимально жизнеспособной функциональности была бы намного лучше, чем полная остановка всей системы. Например, предположим, что в нашем приложении есть конечная точка (URL для сервиса или определенная функция), ответственность которой заключается в анализе информации о местоположении на изображении, загруженном пользователем, из метаданных изображения и предоставлении предложений для тегов местоположения пользователю. Вместо того, чтобы не выполнить всю загрузку, гораздо лучше пропустить эту функциональность и все равно дать пользователю возможность вручную отметить местоположение. Плавная деградация всегда лучше по сравнению с полными сбоями.

#### Тайм-ауты

Мы иногда вызываем другие сервисы или ресурсы, такие как базы данных или конечные точки API в нашем приложении. При вызове такого ресурса из нашего приложения важно всегда иметь разумный тайм-аут. Необязательно даже, чтобы ресурс не справлялся со всеми запросами. Может быть просто так, что конкретный запрос попадает в категорию высокой задержки. Разумный тайм-аут полезен для поддержания согласованного пользовательского опыта - в некоторых случаях лучше потерпеть неудачу, чем иметь разочаровывающе долгие задержки.

#### Экспоненциальные отступления

Когда конечная точка сервиса не работает, повторные попытки - один из способов проверить, был ли это мгновенный сбой. Однако, если повторная попытка также не удастся, нет смысла бесконечно повторять попытки. При достаточно большом масштабе повторные попытки могут конкурировать с новыми запросами (которые вполне могут быть обслужены, как ожидалось) и насытить систему. Чтобы избежать этого, мы можем рассмотреть экспоненциальный отступ для повторных попыток. По сути, это уменьшает скорость, с которой клиенты повторяют попытки, при столкновении с последовательными сбоями при повторных попытках.

#### Прерыватели цепи

В то время как экспоненциальный отступ - один из способов справиться с штормами повторных попыток, прерыватели цепи могут быть другим. Прерыватели цепи могут помочь предотвратить распространение сбоев по всей системе. В противном случае, неослабленный сбой, который проходит через систему, может привести к ложным оповещениям, ухудшая среднее время до обнаружения (MTTD) и среднее время до разрешения (MTTR). Например, в случае, если один из узлов кэша в памяти выходит из строя, что приводит к тому, что запросы достигают базы данных после начальных тайм-аутов для кэша, это может привести к перегрузке базы данных. Если первоначальная связь между сбоем узла кэша и сбоем узла БД не установлена, то это может привести к увеличению MTTD фактической причины и, следовательно, MTTR.

#### Самовосстанавливающиеся системы

Традиционно балансируемое приложение с несколькими экземплярами может выйти из строя, когда более чем пороговое значение экземпляров перестает отвечать на запросы - либо потому, что они не работают, либо внезапно возникает огромный приток запросов, что приводит к ухудшению производительности. Самовосстанавливающаяся система добавляет больше экземпляров в этом сценарии для замены неисправных экземпляров.
Автомасштабирование, подобное этому, также может помочь, когда есть внезапный всплеск запросов. Если наше приложение работает в публичном облаке, это может быть просто вопрос запуска большего количества виртуальных машин. Если мы работаем на месте из нашего центра обработки данных, то нам придется гораздо более тщательно думать о планировании мощностей. Независимо от того, как мы справляемся с добавлением дополнительной мощности - простого добавления может быть недостаточно. Мы также должны думать о дополнительных потенциальных режимах отказа, которые могут быть встречены. Например, сам слой балансировки нагрузки может нуждаться в масштабировании, чтобы справиться с притоком новых бэкендов.

### Заключение

Мы рассмотрели проектирование системы с нуля, масштабируя ее от одного сервера до нескольких центров обработки данных и сотен тысяч пользователей. Однако вы могли (справедливо!) догадаться, что в системном проектировании есть гораздо больше, чем то, что мы рассмотрели до сих пор. Этот курс должен дать вам беглый взгляд на вещи, которые являются фундаментальными для любого процесса системного проектирования. Конкретные реализованные решения, используемые фреймворки и системы оркестрации быстро развиваются. Однако руководящие принципы остаются теми же. Мы надеемся, что этот курс помог вам начать движение в правильном направлении и что вы получите удовольствие от проектирования систем и решения интересных проблем.

## Сетевые технологии

### Введение

Этот раздел будет охватывать, как инфраструктура центра обработки данных разделена для различных потребностей приложений, а также соображения при принятии решения о том, где разместить приложение. Они будут в основном основаны на безопасности, масштабе, RTT (задержке), особенностях инфраструктуры.

Каждая из этих тем будет рассмотрена подробно:

Безопасность - Будет охватывать векторы угроз, с которыми сталкиваются сервисы, обращенные к внешним/внутренним клиентам. Потенциальные варианты смягчения, которые следует учитывать при их развертывании. Это коснется периметровой безопасности, защиты от DDoS, разграничения сети и ограждения кластеров серверов.

Масштаб - Развертывание крупномасштабных приложений требует лучшего понимания возможностей инфраструктуры с точки зрения доступности ресурсов, доменов отказа, вариантов масштабирования, таких как использование anycast, балансировщика нагрузки уровня 4/7, балансировки нагрузки на основе DNS.

RTT (задержка) - Задержка играет ключевую роль в определении общей производительности распределенного сервиса/приложения, где вызовы осуществляются между хостами для обслуживания пользователей.

Особенности инфраструктуры - Некоторые аспекты, которые следует учитывать, это поддерживает ли базовая инфраструктура центра обработки данных отказоустойчивость ToR, т.е. такие функции, как объединение ссылок (bonds), BGP, поддержка сервиса anycast, балансировщик нагрузки, брандмауэр, качество обслуживания.

### Безопасность

Безопасность является одним из основных соображений в любой инфраструктуре. Существуют различные угрозы безопасности, которые могут привести к краже данных, потере сервиса, мошеннической деятельности и т.д. Злоумышленник может использовать такие методы, как фишинг, спам, вредоносное ПО, DoS/DDoS, эксплуатация уязвимостей, атака "человек посередине" и многие другие. В этом разделе мы рассмотрим некоторые из этих угроз и возможные меры по их смягчению. Поскольку существует множество способов атаки и защиты инфраструктуры, мы сосредоточимся только на некоторых из наиболее распространенных.

#### Защита инфраструктуры

Первым и наиболее важным аспектом для любого администрирования инфраструктуры является выявление различных угроз безопасности, которые могут повлиять на бизнес, работающий над этой инфраструктурой. После того, как известны различные угрозы, необходимо разработать и реализовать механизм защиты безопасности. Некоторые из общих средств защиты инфраструктуры:

#### Периметровая безопасность

Это первая линия защиты в любой инфраструктуре, где фильтруются/блокируются нежелательные/неожиданные потоки трафика в инфраструктуру. Это могут быть фильтры в граничных маршрутизаторах, которые разрешают ожидаемые сервисы (например, трафик порта 443 для веб-сервиса, работающего на HTTPS), или этот фильтр может быть настроен для блокировки нежелательного трафика, например, блокировки портов UDP, если сервисы не зависят от UDP.

#### Смягчение DDoS

Защита от атаки DDoS - еще один важный аспект. Трафик атаки будет выглядеть аналогично подлинным запросам пользователей/клиентов, но с намерением затопить внешне открытое приложение, которое может быть веб-сервером, DNS и т.д. Поэтому важно различать трафик атаки и подлинный трафик, для этого существуют различные методы на уровне приложения, один из таких примеров - использование Captcha на веб-сервисе для перехвата трафика, исходящего от ботов.

#### Разграничение сети

Разграничение сети - еще одна общая стратегия, развернутая в различных сетях, когда приложения группируются на основе их потребностей в безопасности и уязвимости к атаке. Некоторые общие разграничения: внешние/интернет-обращенные узлы группируются в отдельную зону, тогда как узлы, имеющие чувствительные данные, сегрегированы в отдельную зону. И любая коммуникация между этими зонами ограничена с помощью инструментов безопасности для ограничения воздействия на нежелательные хосты/порты. Эти межзонные коммуникационные фильтры иногда называются ограждением. Количество зон, которые нужно создать, варьируется для различных развертываний.

### Масштаб

Построение крупномасштабных приложений - сложная деятельность, которая должна охватывать многие аспекты в проектировании, разработке, а также операционализации. В этом разделе будут рассмотрены соображения, которые следует учитывать при их развертывании.

#### Домены отказа

В любой инфраструктуре сбои из-за проблем с оборудованием или программным обеспечением являются обычным явлением. Хотя они могут быть болезненными с точки зрения доступности сервиса, эти сбои все же происходят, и прагматичной целью было бы попытаться свести эти сбои к минимуму. Поэтому при развертывании любого сервиса необходимо учитывать сбои/недоступность некоторых узлов.

#### Доступность ресурсов

Другим аспектом, который следует учитывать при развертывании приложений в масштабе, является доступность необходимой инфраструктуры и функций, от которых зависит сервис. Например, для отказоустойчивости шкафа, если кто-то решает распределить сервис на 5 шкафов, но сервису нужен балансировщик нагрузки (для распределения входящих соединений на разные серверы), это может стать проблемой, если балансировщики нагрузки не поддерживаются во всех шкафах. Или может быть случай, что недостаточно шкафов (которые соответствуют минимальным требуемым спецификациям для настройки сервиса). Лучший подход в этих случаях - определить требования и пробелы, а затем работать с командой инфраструктуры для их наилучшего решения.

#### Варианты масштабирования

При распределении приложения по разным шкафам входящий трафик к этим сервисам должен быть распределен по этим серверам. Для достижения этого можно рассмотреть следующее:

##### Anycast

Это один из самых быстрых способов развертывания распределения трафика по нескольким шкафам. В этом случае каждый сервер, являющийся частью кластера (где настроен сервис), рекламирует адрес обратной связи (/32 IPv4 или /128 IPv6 адрес) в коммутационную ткань DC (наиболее часто для этой цели используется BGP). Сервис должен быть настроен на прослушивание этого адреса обратной связи. Когда клиенты пытаются подключиться к сервису, они разрешаются в этот виртуальный адрес и пересылают свои запросы. Коммутационная ткань DC распределяет каждый поток в различные доступные следующие переходы (в конечном итоге ко всем серверам в этом кластере сервиса).

##### Балансировщик нагрузки

Еще один общий подход - использование балансировщика нагрузки. Виртуальный IP настраивается в балансировщиках нагрузки, к которому клиент подключается при попытке доступа к сервису. Балансировщик нагрузки, в свою очередь, перенаправляет эти соединения на один из фактических серверов, где работает сервис. Для того, чтобы проверить, находится ли сервер в обслуживаемом состоянии, балансировщик нагрузки выполняет периодические проверки работоспособности, и если они не проходят, балансировщик нагрузки прекращает перенаправлять соединение на эти серверы.

##### Балансировка нагрузки на основе DNS

Это похоже на вышеуказанный подход, с единственной разницей в том, что вместо устройства балансировка нагрузки осуществляется на DNS. Клиенты получают разные IP для подключения, когда они запрашивают DNS-записи сервиса. DNS-сервер должен выполнять проверку работоспособности, чтобы знать, какие серверы находятся в хорошем состоянии.

### RTT (время отклика)

RTT - это мера времени, которое требуется для того, чтобы пакет достиг B из A и вернулся в A. Оно измеряется в миллисекундах. Эта мера играет роль в определении производительности сервисов. Ее влияние наблюдается в вызовах, сделанных между различными серверами/сервисами для обслуживания пользователя, а также в пропускной способности TCP, которая может быть достигнута.

Довольно часто сервис делает несколько вызовов к серверам внутри своего кластера или к различным сервисам, таким как аутентификация, логирование, база данных и т.д., чтобы ответить на каждый запрос пользователя/клиента. Эти серверы могут быть распределены по разным шкафам, иногда даже между разными центрами обработки данных в одном регионе. Такие случаи вполне возможны в облачных решениях, где развертывание распространяется на разные сайты в пределах региона. По мере увеличения RTT время отклика для каждого вызова становится дольше и, таким образом, имеет каскадный эффект на конечный ответ, отправляемый пользователю.

### Особенности инфраструктуры

Как видно в предыдущих разделах, для развертывания приложений в масштабе потребуются определенные возможности, которые должны поддерживаться инфраструктурой. В этом разделе будут рассмотрены различные доступные опции и их пригодность.

#### Подключение ToR

Это один из наиболее частых точек отказа (учитывая масштаб развертывания), существуют различные варианты подключения серверов к ToR. Мы рассмотрим их подробно ниже:

##### Одиночный ToR

Это самый простой из всех вариантов. Где NIC сервера подключен к одному ToR. Преимущество этого подхода в том, что используется минимальное количество портов коммутатора, что позволяет DC-ткани поддерживать быстрый рост серверной инфраструктуры. С другой стороны, серверы могут быть недоступны, если возникает проблема с ToR, ссылкой или NIC. Это больше повлияет на приложения с состоянием, так как существующие соединения будут резко прерваны.

##### Двойной ToR

В этом варианте каждый сервер подключен к двум ToR одного и того же шкафа. Это может быть настроено в режиме активный/пассивный, тем самым обеспечивая отказоустойчивость при сбоях ToR/ссылки/NIC. Отказоустойчивость может быть достигнута либо на уровне 2, либо на уровне 3.

### Заключение

Этот курс должен был дать некоторую предысторию о развертывании сервисов в центре обработки данных и различных параметрах, которые следует учитывать, и доступных решениях. Следует отметить, что каждое из обсуждаемых здесь решений имеет различные плюсы и минусы, поэтому конкретно для сценария/требования должно быть определено и использовано правильное соответствие среди них. Поскольку мы не углублялись в различные технологии/решения в этом курсе, это могло вызвать у читателя любопытство узнать о некоторых темах. Вот некоторые ссылки или онлайн-учебные материалы для дальнейшего обучения.

## Контейнеризация и оркестрация

### Введение

Контейнеры, Docker и Kubernetes - это "крутые" термины, о которых говорят все, кто каким-то образом связан с программным обеспечением. Давайте погрузимся в каждую из этих технологий на достаточной глубине, чтобы понять, в чем весь смысл!

В этом модуле мы говорим о внутренностях и использовании контейнеров: как они реализованы, как контейнеризировать ваше приложение и, наконец, как развертывать контейнеризированные приложения в большом масштабе, не теряя сна. Мы также запачкаем руки, попробовав несколько лабораторных упражнений.

### Что такое контейнеры

Вот популярное определение контейнеров согласно Docker, популярному движку контейнеризации:

> Контейнер - это стандартная единица программного обеспечения, которая упаковывает код и все его зависимости, так что приложение работает быстро и надежно от одной вычислительной среды к другой.

Давайте разберем это. Контейнер - это ваш код, объединенный со всей его средой выполнения. Это включает ваши системные библиотеки, бинарные файлы и конфигурационные файлы, необходимые для запуска вашего приложения.

### Почему контейнеры

Вы можете задаться вопросом, зачем нам нужно упаковывать ваше приложение вместе с его зависимостями. Здесь вступает в игру вторая часть определения:

> ...так что приложение работает быстро и надежно от одной вычислительной среды к другой.

Разработчики обычно пишут код в своей среде разработки (или локальной машине), тестируют его в одной или двух средах постановки/тестирования, прежде чем отправить свой код в производство. В идеале, для надежного тестирования приложений перед отправкой в производство, нам нужно, чтобы все эти среды были единообразными до мелочей (базовая ОС, системные библиотеки и т.д.).

Конечно, идеал трудно достичь, особенно когда мы используем смесь локальной (полный контроль) и облачной инфраструктуры (более ограничительной с точки зрения контроля оборудования и вариантов безопасности), сценарий, который сегодня более распространен.

Именно поэтому нам нужно упаковывать не только код, но и зависимости; чтобы ваше приложение работало надежно независимо от того, на какой инфраструктуре или среде оно работает.

### Разница между виртуальными машинами и контейнерами

Давайте немного отвлечемся и углубимся в историю. В предыдущем разделе мы говорили о том, как контейнеры помогают нам достичь разделения обязанностей. До широкого использования контейнеров виртуализация использовалась для запуска приложений в изолированных средах на одном хосте (она все еще используется сегодня в некоторых случаях).

Простыми словами, виртуализация - это когда мы упаковываем программное обеспечение вместе с копией ОС, на которой оно работает. Этот пакет называется виртуальной машиной (ВМ). Образ ОС, объединенный в ВМ, называется гостевой ОС. Компонент, называемый гипервизором, сидит между гостевой и хост-ОС и отвечает за облегчение доступа к аппаратному обеспечению базовой ОС для гостевой ОС.

Основное внимание здесь уделяется размеру ВМ и контейнеров. ВМ поставляются вместе с копией гостевой операционной системы и поэтому являются тяжеловесными по сравнению с контейнерами. Если вы больше заинтересованы в сравнении ВМ и контейнеров, вы можете проверить эти статьи от Backblaze и NetApp.

В то время как возможно запустить операционную систему на хосте с несовместимым ядром, используя гипервизоры (например, ВМ Windows 10 на CentOS 7), в случаях, когда ядра могут быть общими (например, Ubuntu на CentOS 7), контейнеры предпочтительнее ВМ из-за фактора размера. Совместное использование ядер, как вы увидите позже, также дает контейнерам много преимуществ в производительности по сравнению с ВМ, таких как более быстрая загрузка.

### Как реализованы контейнеры

Мы говорили о том, как контейнеры, в отличие от виртуальных машин, используют то же ядро, что и хост-операционная система, и при этом обеспечивают изолированные среды для запуска приложений. Это достигается без накладных расходов на запуск гостевой операционной системы на хост-ОС, благодаря двум функциям ядра linux, называемым cgroups и пространства имен ядра.

Теперь, когда мы касаемся внутренностей контейнеров, было бы уместно дать более технически точное представление о том, что они из себя представляют. Контейнер - это процесс linux или группа процессов linux, которые ограничены в:
- **видимости** процессов вне контейнера (реализовано с использованием пространства имен)
- **количестве ресурсов**, которые он может использовать (реализовано с использованием cgroups), и
- **системных вызовах**, которые могут быть сделаны из контейнера.

Эти ограничения - то, что заставляет контейнеризированное приложение оставаться изолированным от других процессов, работающих на том же хосте.

### Пространства имен

Видимость процессов внутри контейнера должна быть ограничена внутри него самого. Это то, что делают пространства имен linux. Идея заключается в том, что процессы в пространстве имен не могут влиять на те, которые они не могут "видеть". Процессы, разделяющие одно пространство имен, имеют идентичности, сервис и/или интерфейсы, уникальные для пространства имен, в котором они существуют.

### Cgroups

Cgroup можно определить как набор процессов, использование ресурсов которых измеряется и контролируется. Ресурсы могут быть страницами памяти, дисковым вводом-выводом, ЦП и т.д. Фактически, cgroups классифицируются на основе того, на какой ресурс налагается ограничение и характер действия, предпринимаемого при нарушении ограничения.

### Контейнерные движки

Контейнерные движки облегчают процесс создания и управления контейнерами на хост-машине. Как?

* Рабочий процесс создания контейнера обычно начинается с образа контейнера. Образ контейнера - это упакованная, портативная версия целевого приложения, объединенная со всеми зависимостями для его запуска.
* Эти образы контейнеров либо доступны на хост-машине (хост контейнера) из предыдущих сборок, либо должны быть извлечены из удаленного репозитория образов. Иногда контейнерному движку может потребоваться построить образ контейнера из набора инструкций.
* Наконец, когда образ контейнера получен/построен, контейнерный движок распаковывает образ и создает изолированную среду для приложения в соответствии со спецификациями образа.
* Файлы в образе контейнера затем монтируются в изолированную среду, чтобы запустить приложение внутри контейнера.

### Контейнеризация с Docker

Docker приобрел огромную популярность среди других контейнерных движков с момента его выпуска для публики в 2013 году. Вот некоторые из причин, почему Docker так популярен:

- _Улучшенная портативность_

Контейнеры Docker могут быть отправлены и запущены в разных средах, будь то локальная машина, локальные или облачные экземпляры в форме образов Docker. По сравнению с контейнерами docker, контейнеры LXC имеют больше спецификаций машины.
- _Легче по весу_

Образы Docker легче по сравнению с образами ВМ. Например, размер ВМ Ubuntu 18.04 составляет около 3 ГБ, тогда как образ docker - 45 МБ!

- _Версионирование образов контейнеров_

Docker поддерживает сохранение нескольких версий образов, что облегчает просмотр истории образа и даже откат.

- _Повторное использование образов_

Поскольку образы Docker представлены в виде слоев, один образ может быть использован в качестве базы, на основе которой строятся новые образы. Например, Alpine - это легковесный образ (5 МБ), который обычно используется в качестве базового образа. Слои Docker управляются с помощью драйверов хранения.

- _Поддержка сообщества_

Docker hub - это реестр контейнеров, где любой вошедший в систему может загрузить или скачать образ контейнера. Образы Docker популярных дистрибутивов ОС регулярно обновляются в docker hub и получают большую поддержку сообщества.

### Оркестрация с Kubernetes

Теперь мы наконец подходим к самой ожидаемой части: запуску и управлению контейнерами в масштабе. До сих пор мы видели, как Docker облегчает управление жизненным циклом контейнеров и обеспечивает улучшенную портативность приложений. Docker предоставляет решение для облегчения развертывания контейнеров в большом масштабе (вы можете проверить Docker Swarm, если интересно), которое хорошо интегрируется с контейнерами Docker. Однако Kubernetes стал де-факто инструментом для оркестрации управления микросервисами (как контейнерами) в больших распределенных средах.

Давайте посмотрим на точки интереса для нас, SRE, для использования инструментов оркестрации контейнеров и Kubernetes в частности.

#### Мотивация использования Kubernetes

- _Простота использования_

Хотя с Kubernetes связана крутая кривая обучения, после изучения его можно использовать как универсальный инструмент для управления вашими микросервисами. С помощью одной команды можно развернуть полноценные производственные среды. Желаемое состояние приложения должно быть записано как YAML-манифест, и Kubernetes управляет приложением за вас.

- _Обеспечение оптимального использования ресурсов_

Мы можем указать ограничения на ресурсы, используемые каждым контейнером в развертывании. Мы также можем указать наш выбор узлов, где Kubernetes может планировать развертывание узлов (например, микросервисы с высоким потреблением ЦП могут быть проинструктированы для развертывания на узлах с высокой вычислительной мощностью).

- _Отказоустойчивость_

Самовосстановление встроено в базовые типы ресурсов Kubernetes. Это снимает головную боль проектирования отказоустойчивого приложения с нуля. Это особенно относится к приложениям без состояния.

- _Независимость от инфраструктуры_

Kubernetes не имеет привязки к поставщику. Его можно настроить в нескольких облачных средах или в локальных центрах обработки данных.

- _Сильная поддержка сообщества и документация_

Kubernetes с открытым исходным кодом, и многие технологии, такие как операторы, сервисная сетка и т.д., были созданы сообществом для лучшего управления и мониторинга приложений, оркестрированных Kubernetes.

- _Расширяемость и настраиваемость_

Мы можем создавать наши собственные определения пользовательских ресурсов, которые соответствуют нашему случаю использования для управления приложениями, и использовать Kubernetes для управления ими (с пользовательскими контроллерами).

### Заключение

В этом подмодуле мы совершили путешествие по миру контейнеров, начиная с того, почему мы используем контейнеры, как контейнеры эволюционировали из прошлого виртуальных машин (хотя они ни в коем случае не устарели) и чем они отличаются от виртуальных машин. Затем мы увидели, как реализованы контейнеры с акцентом на cgroups и пространства имен, вместе с некоторыми практическими упражнениями. Наконец, мы завершили наше путешествие оркестрацией контейнеров, где мы узнали немного о Kubernetes с некоторыми практическими примерами.

Надеемся, что этот модуль дает вам достаточно знаний и интереса, чтобы продолжать изучать и применять эти технологии в большей глубине!

## Непрерывная интеграция и непрерывная доставка

### Введение

Непрерывная интеграция и непрерывная доставка, также известные как CI/CD, представляют собой набор процессов, которые помогают в более быстрой интеграции изменений кода программного обеспечения и развертывании для конечного пользователя надежным способом. Более частые интеграции и развертывания помогают сократить жизненный цикл разработки программного обеспечения.
Существуют три практики в CI/CD:

* Непрерывная интеграция
* Непрерывная доставка
* Непрерывное развертывание

### Преимущества CI/CD

1. Значительное сокращение проблем интеграции.
2. Команды могут разрабатывать связное программное обеспечение более быстро.
3. Улучшенное сотрудничество между разработчиками и операционными командами может уменьшить проблемы интеграции в производстве.
4. Более быстрая доставка новых функций с меньшим трением
5. Лучшая отладка производственных проблем и их исправление в следующем выпуске/патче.

### Краткая история CI/CD

Традиционные подходы к разработке существуют уже очень давно. Модель водопада широко использовалась как в крупных, так и в малых проектах и была успешной. Несмотря на успех, у нее есть много недостатков, таких как более длительные циклы времени или доставки.

В то время как несколько членов команды работают над проектом, изменения кода накапливаются и никогда не интегрируются до запланированной даты сборки. Сборка обычно происходит в согласованных циклах, которые варьируются от месяца до квартала. Это приводит к нескольким проблемам интеграции и сбоям сборки, поскольку разработчики работали над своими функциями изолированно.

Это был кошмарный сценарий для операционных команд/для кого-либо, кто должен развертывать новые сборки/выпуски в производственной среде из-за отсутствия надлежащей документации по каждому изменению и требованиям к конфигурации. Таким образом, для успешного развертывания часто требовались горячие исправления и немедленные патчи.

Еще одной большой проблемой было сотрудничество. Редко разработчик встречается с инженерами по эксплуатации и не имеет полного понимания производственной среды. Все эти проблемы привели к более длительным циклам времени для доставки изменений кода.

Методология Agile предписывает доставку инкрементальной доставки функций в нескольких итерациях. Таким образом, разработчики фиксируют свои изменения кода в меньших приращениях и выпускают их чаще. Каждая фиксация кода запускает новую сборку, и проблемы интеграции выявляются гораздо раньше. Это улучшило процесс сборки и тем самым сократило время цикла. Этот процесс известен как *непрерывная интеграция или CI*.

Большой барьер между разработчиками и операционными командами был сокращен с появлением тенденции, когда организации адаптируются к дисциплинам DevOps и SRE. Сотрудничество между разработчиками и операционными командами улучшилось. Более того, использование одних и тех же инструментов и процессов обеими командами улучшило координацию и избежало конфликтующего понимания процесса. Одним из основных драйверов в этом отношении является процесс *непрерывной доставки (CD)*, который обеспечивает инкрементальное развертывание меньших изменений. Существуют несколько предпроизводственных сред, также называемых средами постановки, перед развертыванием в производственных средах.

### CI/CD и DevOps

Термин **DevOps** представляет собой комбинацию команд разработки (Dev) и операций (Ops). То есть объединение разработчиков и операционных команд для большего сотрудничества. Команда разработки часто хочет внедрить больше функций и больше изменений, в то время как операционные команды больше сосредоточены на стабильности приложения в производстве. Изменение всегда воспринимается операционной командой как угроза, поскольку оно может пошатнуть стабильность среды. DevOps называется культурой, которая вводит процессы для уменьшения барьеров между разработчиками и операциями.

Сотрудничество между Dev и Ops позволяет лучше следить за сквозными производственными развертываниями и более частыми развертываниями. Таким образом, CI/CD является ключевым элементом в процессах DevOps.

### Непрерывная интеграция

CI - это практика разработки программного обеспечения, где члены команды часто интегрируют свою работу. Каждая интеграция проверяется автоматизированной сборкой (включая тест) для обнаружения ошибок интеграции как можно быстрее.

Непрерывная интеграция требует, чтобы все изменения кода поддерживались в едином репозитории кода, где все члены могут регулярно отправлять изменения в свои ветки функций. Изменения кода должны быстро интегрироваться с остальным кодом, и автоматизированные сборки должны происходить и давать обратную связь члену для раннего разрешения.

Должен быть CI-сервер, где он может запустить сборку, как только код отправлен членом. Сборка обычно включает компиляцию кода и преобразование его в исполняемый файл, такой как JAR или DLL и т.д., называемый упаковкой. Она также должна выполнять модульные тесты с покрытием кода. Опционально, процесс сборки может иметь дополнительные этапы, такие как статический анализ кода и проверки уязвимостей и т.д.

Jenkins, Bamboo, Travis CI, GitLab, Azure DevOps и т.д. - это несколько популярных инструментов CI. Эти инструменты предоставляют различные плагины и интеграцию, такие как ant, maven и т.д. для сборки и упаковки, и Junit, selenium и т.д. для выполнения модульных тестов. SonarQube может быть использован для статического анализа кода и безопасности кода.

### Непрерывная доставка и развертывание

***Непрерывная доставка*** означает более частое развертывание сборок приложений в непроизводственных средах, таких как SIT, UAT, INT, и автоматическое выполнение интеграционных тестов и приемочных тестов.

В CD тесты выполняются на интегрированном приложении вместо одного микросервиса в случаях приложения на основе микросервисов. Тесты должны включать все функциональные тесты и приемочные тесты, которые могут содержать тесты пользовательского интерфейса. Сборка должна быть неизменной по своей природе, то есть один и тот же пакет должен быть развернут во всех средах, включая производство.

Развертывание в производстве часто выполняется вручную после выполнения дополнительных приемочных тестов, таких как тесты производительности и т.д. Таким образом, полностью автоматизированное развертывание в производственных средах называется ***непрерывным развертыванием*** (тогда как ***CD – непрерывная доставка*** не развертывает автоматически в производство). Непрерывное развертывание должно иметь переключатель функций, чтобы функцию можно было отключить без необходимости повторного развертывания кода.

Часто развертывание включает более одной производственной среды, например, в сине-зеленых средах приложение сначала развертывается в синей среде, а затем в зеленой среде, чтобы не требовалось время простоя.

### CI/CD конвейер на основе Jenkins

Jenkins - это сервер непрерывной интеграции с открытым исходным кодом для оркестрации конвейеров CI/CD. Он поддерживает интеграцию с несколькими компонентами, инфраструктурой, такой как git, облако и т.д., что помогает в полном жизненном цикле разработки программного обеспечения.

### Заключение

Мониторинг, автоматизация и устранение рутинной работы - некоторые из основных столпов дисциплины SRE. Как SRE, вам может потребоваться тратить около 50% времени на автоматизацию повторяющихся задач и устранение рутинной работы. Конвейеры CI/CD - один из важнейших инструментов для SRE. Они помогают в доставке качественного приложения с меньшими и регулярными и более частыми сборками. Кроме того, метрики CI/CD, такие как время развертывания, коэффициент успеха, время цикла и коэффициент успеха автоматизированных тестов и т.д., являются ключевыми вещами, за которыми нужно следить, чтобы улучшить качество продукта, тем самым повышая надежность приложений.

* Инфраструктура как код - одна из стандартных практик, следуемых в SRE для автоматизации повторяющихся задач конфигурации. Каждая конфигурация поддерживается как код, поэтому она может быть развернута с использованием конвейеров CI/CD. Важно доставлять изменения конфигурации в производственные среды через конвейеры CI/CD для поддержания версионирования, согласованности изменений в средах и избегания ручных ошибок.
* Часто, как SRE, вам требуется просматривать конвейеры CI/CD приложения и рекомендовать дополнительные этапы, такие как статический анализ кода и проверки безопасности и конфиденциальности в коде для улучшения безопасности и надежности продукта.

В этой главе мы изучили конвейеры CI/CD с краткой историей о проблемах с традиционными практиками сборки. Мы также рассмотрели, как конвейеры CI/CD дополняют дисциплину SRE. Использование конвейеров CI/CD в жизненном цикле разработки программного обеспечения - это современный подход в области SRE, который помогает достичь большей эффективности.

Мы также выполнили практическую лабораторную деятельность по созданию конвейера CI/CD с использованием Jenkins.

## Linux: промежуточный уровень

### Введение

Этот курс разделен на два раздела. В первом разделе мы рассмотрим, где мы остановились в основах Linux, ранее в учебной программе School of SRE, мы углубимся в некоторые из более продвинутых команд и концепций Linux.
 
Во втором разделе мы обсудим, как мы используем Bash-скриптинг в повседневной работе, автоматизации и сокращении рутинной работы как SRE с помощью реальных примеров любого SRE.

### Управление пакетами

#### Введение 

Одной из основных особенностей любой операционной системы является способность запускать другие программы и программное обеспечение, и поэтому на сцену выходит управление пакетами. Управление пакетами - это метод установки и поддержки программных программ на любой операционной системе.

#### Пакет

В ранние дни Linux нужно было загружать исходный код любого программного обеспечения и компилировать его для установки и запуска программного обеспечения. По мере того, как пространство Linux становилось более зрелым, было понято, что ландшафт программного обеспечения очень динамичен, и начали распространять программное обеспечение в форме пакетов. Файл пакета - это сжатая коллекция файлов, которая содержит программное обеспечение, его зависимости, инструкции по установке и метаданные о пакете.

#### Зависимости

Редко, когда пакет программного обеспечения является автономным, он зависит от различного программного обеспечения, библиотек и модулей. Эти подпрограммы хранятся и доступны в форме общих библиотек, которые могут обслуживать более одной программы. Эти общие ресурсы называются зависимостями. Управление пакетами выполняет эту сложную работу по разрешению зависимостей и установке их для пользователя вместе с программным обеспечением.

#### Репозиторий

Репозиторий - это место хранения, где хранятся все пакеты, обновления, зависимости. Каждый репозиторий может содержать тысячи пакетов программного обеспечения, размещенных на удаленном сервере, предназначенных для установки и обновления на системах Linux. Мы обычно обновляем информацию о пакете (часто называемую метаданными), запуская "sudo dnf update".

### Устройства хранения

#### Введение

Устройства хранения - это устройства, которые используются для хранения данных и информации. Linux имеет удивительные возможности, когда дело доходит до обработки внешних устройств, включая устройства хранения. Существует много видов устройств хранения: физические устройства хранения, такие как жесткие диски, виртуальные устройства хранения, такие как RAID или LVM, сетевое хранилище и так далее.

В этом разделе мы научимся работать с любым устройством хранения и настраивать его в соответствии с нашими потребностями.

#### RAID

RAID или "Избыточные массивы независимых дисков" - это техника, которая распределяет ввод-вывод по нескольким дискам для достижения повышенной производительности и избыточности данных. RAID имеет способность увеличивать общую производительность диска и выживать при сбоях диска. Программный RAID использует ЦП компьютера для выполнения операций RAID, тогда как аппаратный RAID использует специализированные процессоры на контроллерах дисков для управления дисками. Три основные особенности RAID - это зеркалирование, полосование и четность.

### Архивирование и резервное копирование

#### Введение
Одна из вещей, которую SRE обеспечивают, - это то, что сервисы работают все время (по крайней мере, 99,99% времени), но объем данных, генерируемых на каждом сервере, запускающем эти сервисы, огромен. Эти данные могут быть логами, пользовательскими данными в базе данных или любым другим видом метаданных. Поэтому нам нужно сжимать, архивировать, ротировать и резервировать данные своевременно для безопасности данных и чтобы убедиться, что у нас не заканчивается место.

#### Архивирование

Мы обычно архивируем данные, которые больше не нужны, но хранятся в основном для целей соответствия. Это помогает хранить данные в сжатом формате, экономя много места. Ниже раздел для ознакомления с инструментами и командами архивирования.

#### Резервное копирование

Резервное копирование - это процесс копирования/дублирования существующих данных. Это резервное копирование может быть использовано для восстановления набора данных в случае потери данных. Резервное копирование данных также становится критическим, когда данные не нужны в повседневной работе, но могут быть использованы в качестве источника истины и для целей соответствия в будущем. Различные типы резервного копирования:

### Введение в Vim

#### Введение
Как SRE мы несколько раз входим на серверы и вносим изменения в файл конфигурации, редактируем и модифицируем скрипты, и редактор, который приходит на помощь и доступен почти во всех дистрибутивах Linux, - это Vim. Vim - это редактор с открытым исходным кодом и бесплатный командной строки, широко принятый и используемый. Мы увидим некоторые основы того, как использовать vim для создания и редактирования файлов. Эти знания помогут нам в понимании следующего раздела, Скриптинг.

### Bash-скриптинг

#### Введение
Как SRE, система Linux находится в центре нашей повседневной работы, и так же и bash-скриптинг. Это язык скриптов, который запускается интерпретатором Linux Bash. До сих пор мы рассмотрели множество функций в основном в командной строке, теперь мы будем использовать эту командную строку как интерпретатор для написания программ, которые облегчат нашу повседневную работу как SRE.

### Заключение

Понимание управления пакетами очень важно как SRE, мы всегда хотим правильный набор программного обеспечения с их совместимыми версиями для работы в гармонии для управления большой инфраструктурой и организацией.

Мы также увидели, как мы можем настраивать и использовать накопители и как мы можем иметь избыточность данных с использованием RAID для избежания потери данных, как данные размещаются на диске и использование файловых систем.

Архивирование и резервное копирование также является важной частью работы SRE. Наша ответственность - хранить данные в безопасности и более эффективным образом.

Bash очень полезен для автоматизации повседневной рутинной работы, с которой сталкивается SRE. Вышеприведенный обзор bash дает нам представление о том, с чего начать, но простое чтение не продвинет вас намного дальше. Я считаю, что "принятие мер и практика темы" даст вам уверенность и поможет вам стать лучшим SRE.

## Системные вызовы и сигналы

### Введение

Курс охватывает фундаментальное понимание сигналов и системных вызовов. Он проливает свет на то, как знание сигналов и системных вызовов может быть полезным для SRE.

### Сигналы

#### Введение в прерывания и сигналы

Прерывание - это событие, которое изменяет нормальный поток выполнения программы и может быть сгенерировано аппаратными устройствами или даже самим ЦП. Когда происходит прерывание, текущий поток выполнения приостанавливается, и запускается обработчик прерываний. После запуска обработчика прерываний предыдущий поток выполнения возобновляется. Существуют три типа событий, которые могут вызвать прерывание ЦП: аппаратные прерывания, программные прерывания и исключения.

Сигналы - это не что иное, как программные прерывания, которые уведомляют процесс о том, что произошло событие. Эти события могут быть запросами от пользователей или указаниями на то, что возникла системная проблема (например, ошибка доступа к памяти). Каждый сигнал имеет номер сигнала и определенное действие по умолчанию. Процесс может реагировать на них любым из следующих способов:

- стандартным (предоставленным ОС) способом
- перехватить сигнал и обрабатывать их программно-определенным способом
- полностью игнорировать сигнал

#### Типы сигналов

Сигналы делятся на две широкие категории. Первый набор составляют традиционные или стандартные сигналы, которые используются ядром для уведомления процессов о событиях. В Linux стандартные сигналы пронумерованы от 1 до 31. Другой набор сигналов состоит из сигналов реального времени. Linux поддерживает как надежные сигналы POSIX (далее "стандартные сигналы"), так и сигналы реального времени POSIX.

#### Отправка сигналов процессу

Существуют три различных способа отправки сигналов процессам:

- Отправка сигнала процессу с использованием kill

Команда kill может быть использована для отправки сигналов процессу. По умолчанию отправляется сигнал SIGTERM, но другой тип сигнала может быть отправлен процессу, определив номер сигнала (или имя сигнала).
Например, команда `kill -9 367` отправляет SIGKILL процессу с PID 367

- Отправка сигнала процессу через клавиатуру 

Сигналы могут быть отправлены запущенному процессу нажатием некоторых специфических клавиш.
Например, удержание Ctrl+C отправляет SIGINT процессу, который завершает его.

- Отправка сигнала процессу через другой процесс 

Процесс может отправить сигнал другому процессу через системный вызов kill(). В этом использовании сигналы могут быть использованы как техника синхронизации или даже как примитивная форма межпроцессного взаимодействия (IPC). Также возможно для процесса отправить сигнал самому себе.
Системный вызов `int kill(pid_t pid, int sig)` принимает 2 аргумента, pid процесса, которому вы хотите отправить сигнал, и номер сигнала желаемого сигнала.

#### Обработка сигналов

Обращаясь к таблице сигналов в предыдущем разделе, вы можете видеть, что есть обработчики по умолчанию, прикрепленные ко всем сигналам, когда программа запускается. Когда мы вызываем сигнал для прикрепления нашего собственного обработчика, мы переопределяем поведение программы по умолчанию в ответ на этот сигнал. В частности, если мы прикрепляем обработчик к SIGINT, программа больше не будет завершаться, когда вы нажимаете <ctrl>+C (или отправляете программе SIGINT любым другим способом); скорее, функция, указанная как обработчик, будет вызвана вместо этого, что определит поведение программы в ответ на этот сигнал.

#### Роль сигналов в системных вызовах на примере wait()

Системный вызов *wait()* ждет, пока один из дочерних процессов вызывающего процесса завершится, и возвращает статус завершения этого дочернего процесса в буфер, на который указывает *statusPtr*.

- Если родительский процесс вызывает системный вызов *wait()*, то выполнение родителя приостанавливается до тех пор, пока дочерний процесс не завершится.
- При завершении дочернего процесса генерируется сигнал SIGCHLD, который доставляется родителю ядром. Сигнал SIGCHLD указывает родителю, что есть некоторая информация о дочернем процессе, которую нужно собрать.
- Родитель, при получении SIGCHLD, собирает статус дочернего процесса из таблицы процессов. Даже если дочерний процесс завершен, в таблице процессов есть запись, соответствующая дочернему процессу, где хранятся запись процесса и PID.
- Когда родитель собирает статус, эта запись удаляется. Таким образом, все следы дочернего процесса удаляются из системы.

### Системные вызовы

#### Введение

Системный вызов - это контролируемая точка входа в ядро, позволяющая процессу запрашивать у ядра выполнение некоторого действия от имени процесса. Ядро делает ряд услуг доступными для программ через интерфейс программирования приложений (API) системных вызовов. Разработчики приложений часто не имеют прямого доступа к системным вызовам, но могут получить к ним доступ через этот API. Эти услуги включают, например, создание нового процесса, выполнение ввода-вывода и создание канала для межпроцессного взаимодействия. Набор системных вызовов фиксирован. Каждый системный вызов идентифицируется уникальным номером.

Системный вызов изменяет состояние процессора с пользовательского режима на режим ядра, так что ЦП может получить доступ к защищенной памяти ядра. Каждый системный вызов может иметь набор аргументов, которые указывают информацию, которая должна быть передана из пользовательского пространства (т.е. виртуального адресного пространства процесса) в пространство ядра и наоборот. С точки зрения программирования, вызов системного вызова выглядит очень похоже на вызов функции C.

#### Типы системных вызовов

Существует в основном 5 типов различных системных вызовов. Они:

- Управление процессами: Эти системные вызовы используются для обработки задач, связанных с процессом, таких как создание процесса, завершение и т.д.
- Управление файлами: Эти системные вызовы используются для операций с файлами, таких как чтение/запись файла.
- Управление устройствами: Эти системные вызовы используются для работы с устройствами, такими как чтение/запись в буферы устройств.
- Поддержка информации: Эти системные вызовы обрабатывают информацию и ее передачу между операционной системой и пользовательской программой.
- Коммуникация: Эти системные вызовы полезны для межпроцессного взаимодействия. Они также используются для создания и удаления соединения связи.

#### Пользовательский режим, режим ядра и их переходы

Современные архитектуры процессоров обычно позволяют ЦП работать по крайней мере в двух различных режимах: пользовательском режиме и режиме ядра. Соответственно, области виртуальной памяти могут быть помечены как часть пользовательского пространства или пространства ядра. При работе в пользовательском режиме ЦП может получить доступ только к памяти, которая помечена как находящаяся в пользовательском пространстве; попытки доступа к памяти в пространстве ядра приводят к аппаратному исключению.

В любой момент времени процесс может выполняться либо в пользовательском режиме, либо в режиме ядра. Тип инструкций, которые могут быть выполнены, зависит от режима, и это обеспечивается на аппаратном уровне. Режимы ЦП (также называемые режимами процессора, состояниями ЦП, уровнями привилегий ЦП) - это операционные режимы для центрального процессора некоторых архитектур компьютеров, которые накладывают ограничения на тип и объем операций, которые могут быть выполнены определенными процессами, запущенными ЦП. Само ядро не является процессом, а менеджером процессов. Модель ядра предполагает, что процессы, которые требуют услуги ядра, используют специфические программные конструкции, называемые системными вызовами.

Когда программа выполняется в пользовательском режиме, она не может напрямую получить доступ к структурам данных ядра или программам ядра. Когда приложение выполняется в режиме ядра, однако, эти ограничения больше не применяются. Программа обычно выполняется в пользовательском режиме и переключается в режим ядра только при запросе услуги, предоставляемой ядром. Если приложению нужен доступ к аппаратным ресурсам в системе (как периферийные устройства, память, диски), оно должно выдать системный вызов, который вызывает переключение контекста с пользовательского режима на режим ядра. Это процедура следует при чтении/записи из/в файлы и т.д. Только сам системный вызов работает в режиме ядра, а не код приложения. Когда системный вызов завершен, процесс возвращается в пользовательский режим с возвращаемым значением, используя обратное переключение контекста.

#### Работа системного вызова write()

Системный вызов *write()* записывает данные в открытый файл.

```
# include <unistd.h>

ssize_t write(int fd, void *buffer, size_t count);
```

*buffer* - это адрес данных, которые нужно записать; *count* - это количество байтов для записи из буфера; и *fd* - это файловый дескриптор, ссылающийся на файл, в который должны быть записаны данные.

Вызов *write()* записывает до *count* байтов из буфера в открытый файл, на который ссылается *fd*. При успехе вызов *write()* возвращает количество фактически записанных байтов, которое может быть меньше *count*, и возвращает -1 при ошибке. При выполнении ввода-вывода на дисковый файл успешное возвращение из *write()* не гарантирует, что данные были переданы на диск, потому что ядро выполняет буферизацию дискового ввода-вывода, чтобы уменьшить активность диска и ускорить вызовы *write()*. Оно просто копирует данные между буфером пользовательского пространства и буфером в кэше буфера ядра. В какой-то более поздний момент ядро записывает (сбрасывает) свой буфер на диск.

Если, тем временем, другой процесс пытается прочитать эти байты файла, то ядро автоматически поставляет данные из кэша буфера, а не из (устаревшего содержимого) файла. Цель этого дизайна - сделать *write()* быстрым, поскольку они не нуждаются в ожидании (медленной) операции диска. Этот дизайн также эффективен, поскольку он уменьшает количество передач диска, которые ядро должно выполнить.

#### Отладка в Linux с помощью strace

*strace* - это инструмент, используемый для отслеживания перехода между пользовательскими процессами и ядром Linux. Чтобы использовать инструмент, нам нужно убедиться, что он установлен в системе, запустив команду:

```
$ rpm -qa | grep -i strace

strace-4.12-9.el7.x86_64
```

Если вышеуказанная команда не дает никакого вывода, вы можете установить инструмент через:

`$ yum install strace`

Функции, которые являются частью стандартной библиотеки C, известны как библиотечные функции. Цели этих функций очень разнообразны, включая такие задачи, как открытие файла, преобразование времени в удобочитаемый для человека формат и сравнение двух строк символов. Некоторые библиотечные функции наслоены поверх системных вызовов. Часто библиотечные функции предназначены для предоставления более дружественного для вызывающего интерфейса, чем базовый системный вызов. Например, функция *printf()* обеспечивает форматирование вывода и буферизацию данных, тогда как системный вызов *write()* просто выводит блок байтов.

### Заключение

Одной из основных целей SRE является улучшение надежности высокомасштабных систем. Для достижения этого необходимо базовое понимание внутренней работы системы.

Знание о том, как работают сигналы, важно, поскольку они играют большую роль в жизненном цикле процессов. Мы видим использование сигналов в ряде операций над процессами: от создания процесса до его убийства. Знание сигналов особенно важно при их обработке в программах. Если вы предвидите событие, которое вызывает сигналы, вы можете определить функцию-обработчик и сказать операционной системе запустить ее, когда приходит этот конкретный тип сигнала.

Понимание системных вызовов особенно полезно для SRE при отладке любого процесса Linux. Системные вызовы предоставляют точные знания о внутренних функциях операционной системы. Они дают глубокое понимание программистам о функциях библиотеки C, которые реализуют системные вызовы на более низком уровне. С использованием команды *strace* можно легко отлаживать медленные или зависшие процессы.

## Устранение неполадок и повышение производительности системы

### Введение

Устранение неполадок является важной частью операций и разработки. Его нельзя выучить, просто прочитав одну статью или пройдя курс онлайн, это непрерывный процесс обучения, который изучается во время:

* Ежедневных операций и разработки.
* Поиска и исправления ошибок приложений.
* Поиска и исправления системных и сетевых проблем.
* Анализа производительности и улучшений.
* И многого другого.

С точки зрения SRE, ожидается, что они знакомы с определенными темами заранее, чтобы иметь возможность устранять проблемы вокруг одиночных или распределенных систем.

* Хорошо знайте свои ресурсы, понимайте спецификации хоста, такие как ЦП, память, сеть, диск и т.д.
* Понимайте системный дизайн и архитектуру.
* Убедитесь, что важные метрики собираются/отображаются правильно.

Была знаменитая цитата основателей HP - **"То, что измеряется, исправляется"**

Если компоненты системы и метрики производительности тщательно фиксируются, то есть высокий шанс успеха в устранении проблемы на самой ранней стадии.

### Устранение неполадок

Устранение неполадок системных сбоев может быть сложным или утомительным временами. В этой практике нам нужно изучить сквозной поток сервиса, все его нисходящие потоки, анализировать логи, утечку памяти, использование ЦП, ввод-вывод диска, сетевые сбои, проблемы хостов и т.д. Знание определенных практик и инструментов может помочь выяснить и смягчить сбои быстрее. Вот высокоуровневая блок-схема устранения неполадок:

#### Общие практики
Различные системы требуют различных подходов для поиска проблем. Объем этого ограничен, и учитывая проблему, может быть много других точек, которые можно рассмотреть. Следующие пункты рассмотрят некоторые высокоуровневые практики для поиска сбоев веб-приложений и поиска исправлений для них.

**Воспроизведение проблемы**

* Попробуйте сломанный запрос, чтобы воспроизвести проблему, например, попробуйте выполнить http/s запрос, который не работает.
* Проверьте сквозной поток запроса и ищите коды возврата, в основном [3xx, 4xx или 5xx](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes). 3xx в основном о перенаправлениях, 4xx о неавторизованных, плохих запросах, запрещенных и т.д., а 5xx в основном о проблемах на стороне сервера. На основе кода возврата вы можете искать следующий шаг.
* Проблемы на стороне клиента в основном связаны с отсутствующим или ошибочным статическим содержимым, такими как проблемы с JavaScript, плохими изображениями, сломанным JSON из асинхронного вызова и т.д., такие могут привести к неправильному отображению страницы в браузерах.

**Сбор информации**

* Ищите ошибки/исключения в логах приложения, такие как "Не могу выделить память" или OutOfMemoryError, или что-то вроде "ошибка ввода-вывода диска", или ошибка разрешения DNS.
* Проверьте метрики приложения и хоста, ищите аномалии в графиках сервиса и хостов. С какого времени увеличилось использование ЦП, с какого времени увеличилось использование памяти, с какого времени уменьшилось дисковое пространство или увеличился ввод-вывод диска, когда средняя нагрузка начала резко расти и т.д.
* Ищите недавние изменения кода или конфигурации, которые, возможно, ломают систему.

**Понимание проблемы**

* Попробуйте соотнести собранные данные с недавними действиями, например, исключение, появляющееся в логах после развертывания конфигурации/кода.
* Это из-за увеличения QPS? Это плохие SQL-запросы? Требуют ли недавние изменения кода лучшего или большего оборудования?

**Найти решение и применить исправление**

* На основе вышеуказанных выводов ищите быстрое исправление, если возможно, например, откат изменений, если ошибки/исключения коррелируют.
* Попробуйте исправить или горячо исправить код, вероятно, в среде постановки, если вы хотите исправить вперед.
* Попробуйте масштабировать систему, если высокий QPS является причиной сбоя системы, затем попробуйте добавить ресурсы (вычисления, хранилище, память и т.д.) по мере необходимости.
* Оптимизируйте SQL-запросы, если нужно.

**Проверить полный поток запроса**

* Снова выполните запросы и убедитесь, что возвраты успешны (код возврата 2xx).
* Проверьте логи, убедитесь, что больше нет исключений/ошибок, как найдено ранее.
* Убедитесь, что метрики вернулись к норме.

#### Общие проблемы хоста

Чтобы узнать, в порядке ли здоровье хоста или нет, ищите любые сбои оборудования или проблемы с его производительностью, можно попробовать следующее:

* Dmesg -: Показывает недавние ошибки / сбои, выброшенные ядром. Это помогает узнать о сбоях оборудования, если таковые имеются
* ls команды -: lspci, lsblk, lscpu, lsscsi, Эти команды перечисляют информацию о pci, диске, ЦП.
* /var/log/messages -: Показывает ошибки/предупреждения, связанные с системным приложением/сервисом, также показывает проблемы ядра.
* Smartd -: проверяет здоровье диска.

### Важные инструменты

#### Важные команды linux

Знание следующих команд поможет быстрее находить проблемы. Подробное объяснение каждой команды выходит за рамки, пожалуйста, ищите man-страницы или онлайн для получения дополнительной информации и примеров вокруг них.

- Для анализа логов -: grep, sed, awk, cut, tail, head
- Для проверки сети -: nc, netstat, traceroute/6, mtr, ping/6, route, tcpdump, ss, ip
- Для DNS -: dig, host, nslookup
- Для отслеживания системных вызовов -: strace
- Для параллельного выполнения через ssh -: gnu parallel, xargs + ssh.
- Для проверки http/s -: curl, wget
- Для списка открытых файлов -: lsof
- Для изменения атрибутов системного ядра -: sysctl

В случае распределенных систем некоторые хорошие сторонние инструменты могут помочь выполнять команды/инструкции на многих хостах одновременно, например:

- **Инструменты на основе SSH**
    - ClusterSSH: Cluster ssh может помочь вам запустить команду параллельно на многих хостах одновременно.
    - Ansible: Он позволяет вам писать плейбуки ansible, которые вы можете запустить на сотнях/тысячах хостов одновременно.
- **Инструменты на основе агентов**
    - Saltstack: Это фреймворк конфигурации, состояния и удаленного выполнения, предоставляет широкий спектр гибкости пользователям для выполнения модулей на большом количестве хостов одновременно.
    - Puppet: Это автоматизированный административный движок для ваших систем Linux, Unix и Windows, выполняет административные задачи.

#### Инструменты анализа логов

Они могут помочь в написании запросов типа SQL для анализа, анализа логов и предоставить простой пользовательский интерфейс для создания панелей мониторинга, которые могут отображать различные типы графиков на основе определенных запросов.

- ELK: Elasticsearch, Logstash и Kibana, предоставляют пакет инструментов и сервисов, позволяющих анализировать логи, индексировать логи и анализировать логи легко и быстро. После того, как логи/данные проанализированы/отфильтрованы через logstash и проиндексированы в elasticsearch, можно создать динамические панели мониторинга в Kibana за считанные минуты. Такое обеспечивает легкий анализ и корреляцию ошибок/исключений/предупреждений приложения.
- Azure kusto: Azure kusto - это облачный сервис, аналогичный Elasticsearch и Kibana, он позволяет легко индексировать тяжелые логи, предоставляет интерфейс типа SQL для написания запросов и интерфейс для создания динамических панелей мониторинга.

### Повышение производительности

Инструменты производительности являются важной частью жизненного цикла разработки/операций, они очень важны для понимания поведения приложения. SRE обычно использует такие инструменты для оценки того, насколько хорошо будет работать сервис, и соответственно вносит/предлагает улучшения.

#### Команды анализа производительности

Большинство из этих команд необходимо знать для проведения анализа производительности системы или сервиса.

- top -: показывает в реальном времени вид работающей системы, процессов, потоков и т.д.
- htop -: Аналогично команде top, но немного более интерактивно, чем она.
- iotop -: Интерактивный инструмент мониторинга ввода-вывода диска.
- vmstat -: Исследователь статистики виртуальной памяти.
- iostat -: Инструмент мониторинга для статистики ввода-вывода для устройств и разделов.
- free -: Сообщает информацию о физической памяти и памяти подкачки.
- sar -: Отчет о системной активности, сообщает различные метрики, такие как ЦП, диск, память, сеть и т.д.
- mpstat -: Отображает информацию об использовании ЦП и производительности.
- lsof -: Предоставляет информацию о списке открытых файлов, открытых какими процессами.
- perf -: Инструмент анализа производительности.

#### Инструменты профилирования

Профилирование является важной частью анализа производительности сервиса. Существуют различные инструменты профилирования, которые могут помочь выяснить наиболее частые пути кода, отладку, профилирование памяти и т.д. Они могут генерировать тепловую карту для понимания производительности кода при нагрузке.

- FlameGraph: Графики пламени - это визуализация профилированного программного обеспечения, позволяющая быстро и точно идентифицировать наиболее частые пути кода.
- Valgrind: Это инструмент программирования для отладки памяти, обнаружения утечек памяти и профилирования.
- Gprof: Инструмент профилирования GNU использует гибрид инструментирования и выборки. Инструментирование используется для сбора информации о вызовах функций, а выборка используется для сбора информации о профилировании времени выполнения.

#### Бенчмаркинг

Это процесс измерения лучшей производительности сервиса. Например, сколько QPS сервис может обрабатывать, его задержка при увеличении нагрузки, использование ресурсов хоста, loadavg и т.д. Регрессионное тестирование (т.е. нагрузочное тестирование) является обязательным перед развертыванием сервиса в производство.

**Некоторые из известных инструментов -:**

- Apache Benchmark Tool, ab:, Он симулирует высокую нагрузку на веб-приложение и собирает данные для анализа
- Httperf: Он отправляет запросы на веб-сервер с указанной скоростью и собирает статистику. Увеличивайте, пока не найдете точку насыщения.
- Apache JMeter: Это популярный инструмент с открытым исходным кодом для измерения производительности веб-приложений. JMeter - это приложение на основе java, и не только веб-сервер, но вы можете использовать его против PHP, Java, REST и т.д.
- Wrk: Это еще один современный инструмент измерения производительности для нагрузки на ваш веб-сервер и предоставления вам деталей задержки, запросов в секунду, передачи в секунду и т.д.
- Locust: Простой в использовании, программируемый и масштабируемый инструмент тестирования производительности.

**Ограничение -:**

Вышеуказанные инструменты помогают в синтетической нагрузке или стресс-тестировании, но такое не измеряет фактический опыт конечного пользователя, оно не может видеть, как ресурсы конечного пользователя повлияют на производительность приложения, это из-за нехватки памяти, ЦП или плохого подключения к интернету.

#### Масштабирование

Система, спроектированная оптимально, может работать только до определенного предела, в зависимости от доступности ресурсов. Постоянная оптимизация всегда необходима для обеспечения оптимального использования ресурсов на пике. С увеличением QPS системы нуждаются в масштабировании. Мы можем масштабировать либо вертикально, либо горизонтально. Вертикальная масштабируемость имеет свои пределы, так как можно увеличить ЦП, память, диск, GPU и другие спецификации только до определенного предела, тогда как горизонтальная масштабируемость может легко и бесконечно расти с учетом ограничений, налагаемых дизайном приложения и атрибутами среды.

Масштабирование веб-приложения потребует некоторых или всех из следующих -:

- Облегчение нагрузки на сервер путем добавления большего количества хостов.
- Распределение трафика по серверам с использованием балансировщиков нагрузки.
- Масштабирование БД путем шардирования данных и увеличения реплик для чтения.

### Пример устранения неполадок - Утечка памяти

Часто проблемы утечки памяти остаются незамеченными до тех пор, пока сервис не станет неотзывчивым после работы в течение некоторого времени (дни, неделя или даже месяц), пока сервис не будет перезапущен или ошибка не будет исправлена. В таких случаях использование памяти сервисом будет отражаться в возрастающем порядке в графике метрик.

Утечка памяти - это неправильное управление выделениями памяти приложением, где ненужная память не освобождается, со временем объекты продолжают накапливаться в памяти, что приводит к сбою сервиса. Обычно такие неосвобожденные объекты сортируются сборщиком мусора автоматически, но иногда из-за ошибки это не происходит. Отладка помогает выяснить, где большая часть памяти хранения приложения применяется. Затем вы начинаете отслеживать и фильтровать все на основе использования. В случае, если вы найдете объекты, которые не используются, но на них есть ссылки, вы можете избавиться от них, удалив их, чтобы избежать утечек памяти.

### Заключение

Сложные системы имеют много факторов, которые могут пойти не так. Это может быть плохой дизайн и архитектура, плохо управляемый код, плохие политики вокруг различных кэшей, плохие запросы к БД или архитектура, неправильное использование ресурсов, или плохая версия ОС, плохо контролируемая система, проблемы центра обработки данных, сетевые сбои и многое другое, любое из этих может пойти не так.

Как SRE, знание важных инструментов/команд, лучших практик, профилирования, бенчмаркинга и масштабирования может помочь вам с более быстрым устранением неполадок и улучшением производительности всей системы.
