# Основы Linux

## Настройка лабораторной среды

- Установите Docker на вашу систему - [https://docs.docker.com/engine/install/](https://docs.docker.com/engine/install/) ИЛИ вы можете использовать онлайн [Docker playground](https://labs.play-with-docker.com/)

- Мы будем выполнять все команды на системе Red Hat Enterprise Linux (RHEL) 8.

  ![](images/linux/admin/image19.png)

- Мы будем запускать большинство команд, используемых в этом модуле, в вышеуказанном контейнере Docker.

## Многопользовательские операционные системы

Операционная система считается многопользовательской, если она позволяет нескольким людям/пользователям использовать компьютер, не влияя на файлы и настройки друг друга. Операционные системы на базе Linux по своей природе являются многопользовательскими, поскольку позволяют нескольким пользователям одновременно получать доступ к системе. Обычный компьютер имеет только одну клавиатуру и монитор, но несколько пользователей могут войти в систему через SSH, если компьютер подключен к сети. Мы расскажем подробнее об SSH позже.

Как администратор сервера, мы в основном имеем дело с серверами Linux, которые физически находятся на очень большом расстоянии от нас. Мы можем подключаться к этим серверам с помощью методов удаленного входа, таких как SSH.

Поскольку Linux поддерживает нескольких пользователей, нам нужен метод, который может защитить пользователей друг от друга. Один пользователь не должен иметь возможность получать доступ и изменять файлы других пользователей.

## Управление пользователями/группами

- Пользователи в Linux имеют связанный с ними идентификатор пользователя, называемый UID.

- Пользователи также имеют домашний каталог и оболочку входа, связанные с ними.

- Группа - это набор из одного или нескольких пользователей. Группа упрощает совместное использование разрешений среди группы пользователей.

- Каждая группа имеет идентификатор группы, называемый GID.

### Команда id

Команда `id` может использоваться для поиска `uid` и `gid`, связанных с пользователем.
Она также перечисляет группы, к которым принадлежит пользователь.

`uid` и `gid`, связанные с пользователем root, равны 0.

![](images/linux/admin/image30.png)

Хороший способ узнать текущего пользователя в Linux - использовать команду `whoami`.

![](images/linux/admin/image35.png)

**Пользователь `root` или суперпользователь - это самый привилегированный пользователь с**
**неограниченным доступом ко всем ресурсам системы. Он имеет UID 0**

### Важные файлы, связанные с пользователями/группами

| Файлы        | Описание                                                                            |
|--------------|----------------------------------------------------------------------------------------|
| /etc/passwd  | Хранит имя пользователя, `uid`, `gid`, домашний каталог, оболочку входа и т.д.  |
| /etc/shadow  | Хранит пароль, связанный с пользователями                                          |
| /etc/group   | Хранит информацию о различных группах в системе                                |

![](images/linux/admin/image23.png)

![](images/linux/admin/image21.png)

![](images/linux/admin/image9.png)

Если вы хотите понять каждое поле, обсуждаемое в приведенных выше выводах, вы можете ознакомиться со следующими ссылками:

- [https://tldp.org/LDP/lame/LAME/linux-admin-made-easy/shadow-file-formats.html](https://tldp.org/LDP/lame/LAME/linux-admin-made-easy/shadow-file-formats.html)

- [https://tldp.org/HOWTO/User-Authentication-HOWTO/x71.html](https://tldp.org/HOWTO/User-Authentication-HOWTO/x71.html)

## Важные команды для управления пользователями

Некоторые из команд, которые часто используются для управления пользователями/группами
в Linux, следующие:

- `useradd` - Создает нового пользователя
- `passwd` - Добавляет или изменяет пароли для пользователя
- `usermod` - Изменяет атрибуты пользователя
- `userdel` - Удаляет пользователя

### useradd

Команда `useradd` добавляет нового пользователя в Linux.

Мы создадим нового пользователя `shivam`. Мы также проверим, что пользователь
был создан, просмотрев файл `/etc/passwd`. `uid` и `gid` равны
1000 для вновь созданного пользователя. Домашний каталог, назначенный пользователю,
это `/home/shivam`, а назначенная оболочка входа - `/bin/bash`. Обратите внимание, что
домашний каталог пользователя и оболочка входа могут быть изменены позже.

![](images/linux/admin/image41.png)

Если мы не указываем никаких значений для атрибутов, таких как домашний каталог или
оболочка входа, будут назначены значения по умолчанию. Мы также можем
переопределить эти значения по умолчанию при создании нового пользователя.

![](images/linux/admin/image54.png)

### passwd

Команда `passwd` используется для создания или изменения паролей для пользователя.

В приведенных выше примерах мы не назначили никаких паролей для пользователей
`shivam` или `amit` при их создании.

`!!` в записи учетной записи в shadow означает, что учетная запись пользователя
была создана, но еще не получила пароль.

![](images/linux/admin/image13.png)

Теперь попробуем создать пароль для пользователя `shivam`.

![](images/linux/admin/image55.png)

Не забудьте пароль, так как мы будем использовать его позже в примерах,
где это будет полезно.

Также давайте изменим пароль для пользователя root. Когда мы переключаемся
с обычного пользователя на пользователя root, система запросит пароль.
Также при входе в систему с использованием пользователя root будет запрошен пароль.

![](images/linux/admin/image39.png)

### usermod

Команда `usermod` используется для изменения атрибутов пользователя, таких как
домашний каталог или оболочка.

Давайте попробуем изменить оболочку входа пользователя `amit` на `/bin/bash`.

![](images/linux/admin/image17.png)

Аналогичным образом вы можете изменить многие другие атрибуты для пользователя.
Попробуйте `usermod -h` для списка атрибутов, которые вы можете изменить.

### userdel

Команда `userdel` используется для удаления пользователя в Linux. После удаления пользователя
вся информация, связанная с этим пользователем, будет удалена.

Давайте попробуем удалить пользователя `amit`. После удаления пользователя вы
не найдете записи для этого пользователя в файле `/etc/passwd` или `/etc/shadow`.

![](images/linux/admin/image34.png)

## Важные команды для управления группами

Команды для управления группами очень похожи на команды, используемые для управления пользователями. Каждая команда здесь не объясняется подробно, так как они довольно похожи. Вы можете попробовать запустить эти команды в своей системе.

| Команда                | Описание                     |
| -----------------------| ------------------------------- |
| groupadd <group_name\> | Создает новую группу             |
| groupmod <group_name\> | Изменяет атрибуты группы  |
| groupdel <group_name\> | Удаляет группу                 |
| gpasswd  <group_name\> | Изменяет пароль для группы     |

![](images/linux/admin/image52.png)

Теперь мы попробуем добавить пользователя `shivam` в группу, которую мы создали выше.

![](images/linux/admin/image33.png)

## Становление суперпользователем

**Перед запуском приведенных ниже команд убедитесь, что вы установили
пароль для пользователя `shivam` и пользователя `root` с помощью команды `passwd`,
описанной в предыдущем разделе.**

Команда `su` может использоваться для переключения пользователей в Linux. Теперь давайте попробуем
переключиться на пользователя `shivam`.

![](images/linux/admin/image37.png)

Теперь давайте попробуем открыть файл `/etc/shadow`.

![](images/linux/admin/image29.png)

Операционная система не позволила пользователю `shivam` прочитать содержимое
файла `/etc/shadow`. Это важный файл в Linux, который
хранит пароли пользователей. К этому файлу может получить доступ только `root` или
пользователи, имеющие привилегии `суперпользователя`.


**Команда `sudo` позволяет** **пользователю выполнять команды с привилегиями безопасности
пользователя root.** Помните, что пользователь root имеет все
привилегии в системе. Мы также можем использовать команду `su` для переключения на
пользователя root и открытия вышеуказанного файла, но для этого потребуется
пароль пользователя root. Альтернативный способ, который предпочтителен в большинстве
современных операционных систем, - использовать команду `sudo` для становления
суперпользователем. При таком подходе пользователь должен ввести свой пароль, и они
должны быть частью группы `sudo`.

**Как предоставить суперпривилегии другим пользователям?**

Давайте сначала переключимся на пользователя root с помощью команды `su`. Обратите внимание, что использование
приведенной ниже команды потребует ввода пароля для пользователя root.

![](images/linux/admin/image44.png)

В случае, если вы забыли установить пароль для пользователя root, введите `exit` и
вы вернетесь как пользователь root. Теперь установите пароль с помощью
команды `passwd`.

**Файл `/etc/sudoers` содержит имена пользователей, которым разрешено вызывать
`sudo`**. В операционных системах Red Hat этот файл по умолчанию отсутствует. Нам нужно будет установить `sudo`.

![](images/linux/admin/image3.png)

Мы обсудим команду `yum` подробно в последующих разделах.

Попробуйте открыть файл `/etc/sudoers` в системе. Файл содержит много
информации. Этот файл хранит правила, которым пользователи должны следовать при
запуске команды `sudo`. Например, `root` может запускать любые
команды откуда угодно.

![](images/linux/admin/image8.png)

Один из простых способов предоставить пользователям доступ root - добавить их в группу,
которая имеет разрешения на запуск всех команд. `wheel` - это группа в
Red Hat Linux с такими привилегиями.

![](images/linux/admin/image25.png)

Давайте добавим пользователя `shivam` в эту группу, чтобы он также имел привилегии `sudo`.

![](images/linux/admin/image48.png)

Теперь давайте переключимся обратно на пользователя `shivam` и попробуем получить доступ к
файлу `/etc/shadow`.

![](images/linux/admin/image56.png)

Нам нужно использовать `sudo` перед запуском команды, поскольку доступ к ней можно получить только с
привилегиями `sudo`. Мы уже предоставили привилегии `sudo`
пользователю `shivam`, добавив его в группу `wheel`.


## Разрешения файлов

В операционной системе Linux каждому файлу и каталогу назначаются разрешения доступа
для владельца файла, членов группы связанных пользователей и всех остальных. Это делается для того, чтобы
один пользователь не мог получить доступ к файлам и ресурсам другого пользователя.

Чтобы увидеть разрешения файла, мы можем использовать команду `ls`. Давайте посмотрим
на разрешения файла `/etc/passwd`.

![](images/linux/admin/image40.png)

Давайте рассмотрим некоторые важные поля в выводе, которые
связаны с разрешениями файлов.

![](images/linux/admin/image31.jpg)


![](images/linux/admin/image57.png)

### Команда chmod

Команда `chmod` используется для изменения разрешений файлов и каталогов в
Linux.

Команда `chmod` принимает разрешения в виде числового аргумента. Мы можем
рассматривать разрешение как серию битов, где 1 представляет True или
разрешено, а 0 представляет False или не разрешено.

| Разрешение               | rwx     | Двоичное  |   Десятичное |
| -------------------------| ------- | ------- | --------- |
| Чтение, запись и выполнение  | rwx     | 111     | 7         |
| Чтение и запись           | rw-     | 110     | 6         |
| Чтение и выполнение         | r-x     | 101     | 5         |
| Только чтение                | r--     | 100     | 4         |
| Запись и выполнение        | -wx     | 011     | 3         |
| Только запись               | -w-     | 010     | 2         |
| Только выполнение             | --x     | 001     | 1         |
| Нет                     | ---     | 000     | 0         |

Теперь мы создадим новый файл и проверим разрешения файла.

![](images/linux/admin/image15.png)

Владелец группы не имеет разрешения на запись в этот файл. Давайте
дадим владельцу группы или root разрешение на запись с помощью команды `chmod`.

![](images/linux/admin/image26.png)

Команда `chmod` также может использоваться для изменения разрешений каталога
аналогичным образом.

### Команда chown

Команда `chown` используется для изменения владельца файлов или
каталогов в Linux.

Синтаксис команды: `chown \<new_owner\> \<file_name\>`

![](images/linux/admin/image6.png)

**В случае, если у нас нет привилегий `sudo`, нам нужно использовать команду `sudo`**. Давайте переключимся на пользователя `shivam` и попробуем изменить владельца. Мы
также изменили владельца файла на `root` перед запуском приведенной ниже команды.

![](images/linux/admin/image12.png)

Команда chown также может использоваться для изменения владельца каталога аналогичным
образом.

### Команда chgrp

Команда `chgrp` может использоваться для изменения владельца группы файлов или
каталогов в Linux. Синтаксис очень похож на синтаксис команды `chown`.

![](images/linux/admin/image27.png)

Команда `chgrp` также может использоваться для изменения владельца каталога аналогичным
образом.

## Команда SSH

Команда `ssh` используется для входа в удаленные системы, передачи файлов между системами и для выполнения команд на удаленной машине. `SSH` означает secure shell и используется для обеспечения зашифрованного защищенного соединения между двумя хостами через небезопасную сеть, такую как интернет.

Ссылка:
[https://www.ssh.com/ssh/command/](https://www.ssh.com/ssh/command/)

Теперь мы обсудим аутентификацию без пароля, которая является безопасной и наиболее
часто используется для аутентификации `ssh`.

### Аутентификация без пароля с использованием SSH

Используя этот метод, мы можем `ssh` в хосты без ввода пароля.
Этот метод также полезен, когда мы хотим, чтобы некоторые скрипты выполняли
задачи, связанные с ssh.

Аутентификация без пароля требует использования пары открытого и закрытого ключей. Как следует из названия, открытый ключ может быть передан кому угодно, но закрытый ключ должен храниться в тайне.
Давайте не вдаваться в подробности того, как работает эта аутентификация. Вы можете прочитать об этом
[здесь](https://www.digitalocean.com/community/tutorials/understanding-the-ssh-encryption-and-connection-process)

Шаги для настройки аутентификации без пароля с удаленным хостом:

1. Генерация пары открытого-закрытого ключей  

    **Если у нас уже есть пара ключей, хранящаяся в каталоге `~/.ssh`, нам не нужно генерировать ключи снова.**

    Установите пакет `openssh`, который содержит все команды, связанные с `ssh`.

    ![](images/linux/admin/image49.png)

    Сгенерируйте пару ключей с помощью команды `ssh-keygen`. Можно выбрать
    значения по умолчанию для всех запросов.

    ![](images/linux/admin/image47.png)

    После успешного выполнения команды `ssh-keygen` мы должны увидеть два
    ключа в каталоге `~/.ssh`. `id_rsa` - это закрытый ключ, а
    `id_rsa.pub` - это открытый ключ. Обратите внимание, что закрытый ключ может только
    читаться и изменяться вами.

    ![](images/linux/admin/image7.png)

2. Передача открытого ключа на удаленный хост

    Существует несколько способов передачи открытого ключа на удаленный сервер.
    Мы рассмотрим один из наиболее распространенных способов сделать это с помощью
    команды `ssh-copy-id`.

    ![](images/linux/admin/image11.png)

    Установите пакет `openssh-clients` для использования команды `ssh-copy-id`.

    ![](images/linux/admin/image46.png)

    Используйте команду `ssh-copy-id` для копирования вашего открытого ключа на удаленный хост.

    ![](images/linux/admin/image50.png)

    Теперь выполните `ssh` на удаленный хост, используя аутентификацию по паролю.

    ![](images/linux/admin/image51.png)

    Наш открытый ключ должен быть теперь в `~/.ssh/authorized_keys`.

    ![](images/linux/admin/image4.png)

    `~/.ssh/authorized_key` содержит список открытых ключей. Пользователи,
    связанные с этими открытыми ключами, имеют доступ `ssh` к удаленному
    хосту.


### Как запускать команды на удаленном хосте?

Общий синтаксис: 

```shell
ssh \<user\>@\<hostname/hostip\> \<command\>
```

![](images/linux/admin/image14.png)

### Как передавать файлы с одного хоста на другой хост?

Общий синтаксис:

```shell
scp \<source\> \<destination\>
```

![](images/linux/admin/image32.png)

## Управление пакетами

Управление пакетами - это процесс установки и управления программным обеспечением на
системе. Мы можем устанавливать пакеты, которые нам требуются, из дистрибутива Linux
пакетов. Различные дистрибутивы используют разные системы пакетов.
  
| Системы пакетов      | Дистрибутивы                              |
| ---------------------- | ------------------------------------------ |
| Стиль Debian (`.deb`)  |   Debian, Ubuntu                           |
| Стиль Red Hat (`.rpm`) |   Fedora, CentOS, Red Hat Enterprise Linux |

**Популярные системы пакетов в Linux**

|Команда                        | Описание                                         |
| ----------------------------- | --------------------------------------------------- |
| yum install <package_name\>   | Устанавливает пакет в вашу систему                   |
| yum update <package_name\>    | Обновляет пакет до последней доступной версии   |
| yum remove <package_name\>    | Удаляет пакет из вашей системы                  |
| yum search <keyword\>         | Ищет по определенному ключевому слову                   |

[DNF](https://docs.fedoraproject.org/en-US/quick-docs/dnf/) является
преемником YUM, который теперь используется в Fedora для установки и
управления пакетами. DNF может заменить YUM в будущем на всех дистрибутивах Linux на основе RPM.

![](images/linux/admin/image20.png)

Мы нашли точное совпадение для ключевого слова `httpd` при поиске с помощью
команды `yum search`. Теперь давайте установим пакет `httpd`.

![](images/linux/admin/image28.png)

После установки `httpd` мы будем использовать команду `yum remove` для удаления
пакета `httpd`.

![](images/linux/admin/image43.png)

## Управление процессами

В этом разделе мы изучим некоторые полезные команды, которые можно
использовать для мониторинга процессов в системах Linux.

### ps (статус процесса)

Команда `ps` используется для получения информации о процессе или списке
процессов.

![](images/linux/admin/image24.png)

Если вы получаете ошибку "ps command not found" при запуске команды `ps`, установите пакет `procps`.

`ps` без аргументов не очень полезна. Давайте попробуем перечислить все
процессы в системе, используя команду ниже.

Ссылка:
[https://unix.stackexchange.com/questions/106847/what-does-aux-mean-in-ps-aux](https://unix.stackexchange.com/questions/106847/what-does-aux-mean-in-ps-aux)

![](images/linux/admin/image42.png)

Мы можем использовать дополнительный аргумент с командой `ps` для вывода
информации о процессе с определенным идентификатором процесса (PID).

![](images/linux/admin/image2.png)

Мы можем использовать `grep` в сочетании с командой `ps` для вывода только определенных
процессов.

![](images/linux/admin/image1.png)

### top

Команда `top` используется для отображения информации о процессах Linux,
работающих в системе в реальном времени. Она также показывает сводку
системной информации.

![](images/linux/admin/image53.png)

Для каждого процесса `top` перечисляет идентификатор процесса, владельца, приоритет, состояние,
использование ЦП, использование памяти и многое другое. Она также
перечисляет использование памяти и использование ЦП системы в целом
вместе с временем работы системы и средней нагрузкой ЦП.

## Управление памятью

В этом разделе мы изучим некоторые полезные команды, которые можно
использовать для просмотра информации о системной памяти.

### free

Команда `free` используется для отображения использования памяти системы. Эта
команда отображает общее свободное и используемое пространство, доступное в ОЗУ,
вместе с пространством, занятым кэшами/буферами.

![](images/linux/admin/image22.png)

Команда `free` по умолчанию показывает использование памяти в килобайтах. Мы можем использовать
дополнительный аргумент для получения данных в удобочитаемом формате.

![](images/linux/admin/image5.png)

### vmstat

Команда `vmstat` может использоваться для отображения использования памяти вместе с
дополнительной информацией об использовании ввода-вывода и ЦП.

![](images/linux/admin/image38.png)

## Проверка дискового пространства

В этом разделе мы изучим некоторые полезные команды, которые можно
использовать для просмотра дискового пространства в Linux.

### df (disk free)

Команда `df` используется для отображения свободного и доступного пространства для каждой
смонтированной файловой системы.

![](images/linux/admin/image36.png)

### du (disk usage)

Команда `du` используется для отображения использования дискового пространства файлами и каталогами на
системе.

![](images/linux/admin/image10.png)

Приведенная ниже команда может использоваться для отображения 5 самых больших каталогов
в каталоге `root`.

![](images/linux/admin/image18.png)

## Демоны

Компьютерная программа, которая работает как фоновый процесс, называется _демоном_.
Традиционно имя процессов демонов заканчивается на `d` - `sshd`, `httpd`,
и т.д. Мы не можем взаимодействовать с процессом демона, так как они работают в
фоновом режиме.

Службы и демоны часто используются взаимозаменяемо.

## Systemd

`systemd` - это менеджер системы и служб для операционных систем Linux.
Юниты `systemd` являются строительными блоками `systemd`. Эти юниты
представлены файлами конфигурации юнитов.

Приведенные ниже примеры показывают файлы конфигурации юнитов, доступные в
`/usr/lib/systemd/system`, которые распространяются установленными пакетами RPM.
Нас больше интересуют файлы конфигурации, которые заканчиваются на service,
так как это юниты служб.

![](images/linux/admin/image16.png)

### Управление системными службами

Юниты служб заканчиваются расширением файла `.service`. Команда `systemctl` может использоваться
для запуска/остановки/перезапуска служб, управляемых `systemd`.

| Команда                         | Описание                            |
| ------------------------------- | -------------------------------------- |
| systemctl start name.service    | Запускает службу                       |
| systemctl stop name.service     | Останавливает службу                        |
| systemctl restart name.service  | Перезапускает службу                        |
| systemctl status name.service   | Проверяет статус службы          |
| systemctl reload name.service   | Перезагружает конфигурацию службы  |

## Логи 

В этом разделе мы поговорим о некоторых важных файлах и каталогах,
которые могут быть очень полезны для просмотра системных логов и логов приложений
в Linux. Эти логи могут быть очень полезны при устранении неполадок в
системе.

![](images/linux/admin/image58.png)

# Основы командной строки

## Настройка лабораторной среды

Можно использовать онлайн-интерпретатор Bash для запуска всех команд, которые приведены в качестве примеров в этом курсе. Это также поможет вам получить практический опыт работы с различными командами Linux.

[REPL](https://repl.it/languages/bash) - один из популярных онлайн-интерпретаторов Bash для запуска команд Linux. Мы будем использовать его для запуска всех команд, упомянутых в этом курсе.

## Что такое команда

Команда - это программа, которая указывает операционной системе выполнить
определенную работу. Программы хранятся в виде файлов в Linux. Поэтому команда
также является файлом, который хранится где-то на диске.

Команды также могут принимать дополнительные аргументы в качестве входных данных от пользователя.
Эти аргументы называются аргументами командной строки. Знание того, как использовать
команды, важно, и существует множество способов получить помощь в Linux,
особенно для команд. Почти каждая команда будет иметь какую-то форму
документации, большинство команд будет иметь аргумент командной строки `-h` или 
`--help`, который отобразит разумное количество документации. Но самая
популярная система документации в Linux называется страницами `man`&mdash;сокращение от страниц руководства.

Использование `--help` для отображения документации для команды `ls`.

![](images/linux/commands/image19.png)

## Организация файловой системы

Файловая система Linux имеет иерархическую (или древовидную) структуру с
самым высоким уровнем каталога, называемым `root` (обозначается `/`). Каталоги,
присутствующие внутри корневого каталога, хранят файлы, связанные с системой.
Эти каталоги, в свою очередь, могут хранить либо системные файлы, либо файлы приложений,
либо файлы, связанные с пользователем.

![](images/linux/commands/image17.png)

| Каталог  | Описание                                                                    |
|------------|--------------------------------------------------------------------------------| 
| bin        | Исполняемая программа наиболее часто используемых команд находится в каталоге `bin`|
| dev        | Этот каталог содержит файлы, связанные с устройствами в системе                 |
| etc        | Этот каталог содержит все файлы конфигурации системы                     |
| home       | Этот каталог содержит файлы и каталоги, связанные с пользователем                     |       
| lib        | Этот каталог содержит все библиотечные файлы                                  |
| mnt        | Этот каталог содержит файлы, связанные с смонтированными устройствами в системе         |
| proc       | Этот каталог содержит файлы, связанные с запущенными процессами в системе   |
| root       | Этот каталог содержит файлы и каталоги, связанные с пользователем root                | 
| sbin       | Этот каталог содержит программы, используемые для администрирования системы                |
| tmp        | Этот каталог используется для хранения временных файлов в системе                  |
| usr        | Этот каталог используется для хранения программ приложений в системе             |

## Команды для навигации по файловой системе

Существуют три основные команды, которые часто используются для навигации по
файловой системе:

- ls

- pwd

- cd

Теперь мы попытаемся понять, что делает каждая команда и как использовать
эти команды. Вы также должны практиковать приведенные примеры на
онлайн-оболочке Bash.

### pwd (print working directory)

В любой момент времени мы будем находиться в определенном каталоге.
Чтобы получить имя каталога, в котором мы находимся, мы можем использовать
команду `pwd` в Linux.

![](images/linux/commands/image2.png)

Теперь мы будем использовать команду `cd` для перехода в другой каталог, а затем
выведем рабочий каталог.

![](images/linux/commands/image20.png)

### cd (change directory)

Команда `cd` может использоваться для изменения рабочего каталога. Используя
команду, вы можете перемещаться из одного каталога в другой.

В приведенном ниже примере мы изначально находимся в каталоге `root`. Мы
затем использовали команду `cd` для изменения каталога.

![](images/linux/commands/image3.png)

### ls (list files and directories)**

Команда `ls` используется для вывода содержимого каталога. Она выведет
все файлы и папки, присутствующие в данном каталоге.

Если мы просто введем `ls` в оболочке, она выведет все файлы и
каталоги, присутствующие в текущем каталоге.

![](images/linux/commands/image7.png)

Мы также можем указать имя каталога в качестве аргумента для команды `ls`. Она
затем выведет все файлы и каталоги внутри данного каталога.

![](images/linux/commands/image4.png)

## Команды для манипуляции файлами

Существуют пять основных команд, которые часто используются для манипуляции
файлами:

- touch

- mkdir

- cp

- mv

- rm

Теперь мы попытаемся понять, что делает каждая команда и как использовать
эти команды. Вы также должны практиковать приведенные примеры на
онлайн-оболочке Bash.

### touch (create new file)

Команда `touch` может использоваться для создания нового пустого файла.
Эта команда очень полезна для многих других целей, но мы обсудим
самый простой случай использования создания нового файла.

Общий синтаксис использования команды `touch`:

```shell
touch <file_name>
```

![](images/linux/commands/image9.png)

### mkdir (create new directories)

Команда `mkdir` используется для создания каталогов. Вы можете использовать команду `ls`
для проверки того, что новый каталог создан.

Общий синтаксис использования команды `mkdir`:

```shell
mkdir <directory_name>
```

![](images/linux/commands/image11.png)

### rm (delete files and directories)

Команда `rm` может использоваться для удаления файлов и каталогов. Очень
важно отметить, что эта команда навсегда удаляет файлы и
каталоги. Почти невозможно восстановить эти файлы и
каталоги после успешного выполнения команды `rm`. Запускайте
эту команду с осторожностью.

Общий синтаксис использования команды `rm`:

```shell
rm <file_name>
```

Давайте попробуем понять команду `rm` на примере. Мы попробуем
удалить файл и каталог, которые мы создали с помощью команд `touch` и `mkdir`
соответственно.

![](images/linux/commands/image18.png)

### cp (copy files and directories)

Команда `cp` используется для копирования файлов и каталогов из одного места
в другое. Обратите внимание, что команда `cp` не вносит никаких изменений в
оригинальные файлы или каталоги. Оригинальные файлы или каталоги и
их копия сосуществуют после успешного выполнения команды `cp`.

Общий синтаксис использования команды `cp`:

```shell
cp <source_path> <destination_path>
```

В настоящее время мы находимся в каталоге `/home/runner`. Мы будем использовать команду `mkdir`
для создания нового каталога с именем `test_directory`. Теперь мы
попробуем скопировать файл `_test_runner.py` в каталог, который мы только что
создали.

![](images/linux/commands/image23.png)

Обратите внимание, что с оригинальным файлом `_test_runner.py` ничего не произошло.
Он все еще находится в текущем каталоге. Новая копия была создана
внутри `test_directory`.

![](images/linux/commands/image14.png)

Мы также можем использовать команду `cp` для копирования целого каталога из одного
места в другое. Давайте попробуем понять это на примере.

![](images/linux/commands/image12.png)

Мы снова использовали команду `mkdir` для создания нового каталога с именем
`another_directory`. Затем мы использовали команду `cp` вместе с
дополнительным аргументом `-r` для копирования `test_directory`.

**mv (move files and directories)**

Команда `mv` может использоваться либо для перемещения файлов или каталогов из одного
места в другое, либо для переименования файлов или каталогов. Обратите
внимание, что перемещение файлов и их копирование - это очень разные вещи. При
перемещении файлов и каталогов оригинальная копия теряется.

Общий синтаксис использования команды `mv`:

```shell
mv <source_path> <destination_path>
```

В этом примере мы будем использовать команду `mv` для перемещения
файла `_test_runner.py` в `test_directory`. В этом случае этот файл
уже существует в `test_directory`. Команда `mv` просто заменит его.
**Обратите внимание, что оригинальный файл не существует в текущем каталоге
после успешного выполнения команды `mv`.**

![](images/linux/commands/image26.png)

Мы также можем использовать команду `mv` для перемещения каталога из одного места
в другое. В этом случае нам не нужно использовать флаг `-r`, который мы использовали
при использовании команды `cp`. Обратите внимание, что оригинальный каталог не будет
существовать, если мы используем команду `mv`.

Одно из важных применений команды `mv` - переименование файлов и
каталогов. Давайте посмотрим, как мы можем использовать эту команду для переименования.

Мы сначала изменили наше местоположение на `test_directory`. Затем мы используем
команду `mv` для переименования файла `_test_runner.py` в `test.py`.

![](images/linux/commands/image29.png)

## Команды для просмотра файлов

Существуют пять основных команд, которые часто используются для просмотра
файлов:

- cat

- head

- tail

- more

- less

Теперь мы попытаемся понять, что делает каждая команда и как использовать
эти команды. Вы также должны практиковать приведенные примеры на
онлайн-оболочке Bash.

Мы создадим новый файл с именем `numbers.txt` и вставим числа от 1
до 100 в этот файл. Каждое число будет в отдельной строке.

![](images/linux/commands/image21.png)

Не беспокойтесь о приведенной выше команде сейчас. Это продвинутая команда, которая
используется для генерации чисел. Затем мы использовали оператор перенаправления для
передачи этих чисел в файл. Мы будем обсуждать перенаправление ввода-вывода в
последующих разделах.


### cat

Самое простое использование команды `cat` - вывести содержимое файла на
ваш экран вывода. Эта команда очень полезна и может использоваться для многих
других целей. Мы изучим другие случаи использования позже.

![](images/linux/commands/image1.png)

Вы можете попробовать запустить приведенную выше команду, и вы увидите числа,
выведенные от 1 до 100 на вашем экране. Вам нужно будет прокрутить вверх, чтобы просмотреть
все числа.

### head

Команда `head` отображает первые 10 строк файла по умолчанию. Мы
можем включить дополнительные аргументы для отображения стольких строк, сколько мы хотим
с начала.

В этом примере мы видим только первые 10 строк из
файла при использовании команды `head`.

![](images/linux/commands/image15.png)

По умолчанию команда `head` будет отображать только первые 10 строк. Если мы
хотим указать количество строк, которые мы хотим увидеть с начала, используйте
аргумент `-n` для ввода.

![](images/linux/commands/image16.png)

### tail

Команда `tail` отображает последние 10 строк файла по умолчанию. Мы
можем включить дополнительные аргументы для отображения стольких строк, сколько мы хотим
с конца файла.

![](images/linux/commands/image22.png)

По умолчанию команда `tail` будет отображать только последние 10 строк. Если мы
хотим указать количество строк, которые мы хотим увидеть с конца, используйте аргумент `-n`
для ввода.

![](images/linux/commands/image10.png)

В этом примере мы видим только последние 5 строк из файла
при использовании команды `tail` с явной опцией `-n`.


### more

Команда `more` отображает содержимое файла или вывод команды, 
отображая один экран за раз в случае, если файл большой (например, файлы журналов).
Она также позволяет навигацию вперед и ограниченную навигацию назад в файле.

![](images/linux/commands/image33.png)

Команда `more` отображает столько, сколько может поместиться на текущем экране, и ждет ввода пользователя для продолжения. Навигация вперед может быть выполнена нажатием клавиши `Enter`, которая продвигает вывод на одну строку, и клавиши `Space`, которая продвигает вывод на один экран.

### less

Команда `less` является улучшенной версией `more`. Она отображает содержимое файла или вывод команды, по одной странице за раз.
Она позволяет навигацию как назад, так и вперед в файле, а также имеет опции поиска. Мы можем использовать `клавиши со стрелками` для продвижения назад или вперед на одну строку. Для перемещения вперед на одну страницу нажмите `Space`, а для перемещения назад на одну страницу нажмите `b` на клавиатуре.
Вы можете мгновенно перейти к началу и концу файла.


## Команда Echo в Linux

Команда `echo` - одна из самых простых команд, которые используются в
оболочке. Эта команда эквивалентна `print` в других
языках программирования.

Команда `echo` выводит заданную входную строку на экран.

![](images/linux/commands/image34.png)

## Команды обработки текста

В предыдущем разделе мы узнали, как просматривать содержимое файла.
Во многих случаях мы будем заинтересованы в выполнении следующих операций:

- Вывести только строки, которые содержат определенное слово(а)

- Заменить определенное слово другим словом в файле

- Отсортировать строки в определенном порядке

Существуют три основные команды, которые часто используются для обработки
текстов:

- grep

- sed

- sort

Теперь мы попытаемся понять, что делает каждая команда и как использовать
эти команды. Вы также должны практиковать приведенные примеры на
онлайн-оболочке Bash.

Мы создадим новый файл с именем `numbers.txt` и вставим числа от 1
до 10 в этот файл. Каждое число будет в отдельной строке.

![](images/linux/commands/image8.png)

### grep

Команда `grep` в своей простейшей форме может использоваться для поиска определенных
слов в текстовом файле. Она отобразит все строки в файле, которые
содержат определенный ввод. Слово, которое мы хотим найти, предоставляется в качестве
ввода для команды `grep`.

Общий синтаксис использования команды `grep`:

```shell
grep <word_to_search> <file_name>
```

В этом примере мы пытаемся найти строку "1" в этом файле.
Команда `grep` выводит строки, где она нашла эту строку.

![](images/linux/commands/image36.png)

### sed

Команда `sed` в своей простейшей форме может использоваться для замены текста в
файле.

Общий синтаксис использования команды `sed` для замены:

```shell
sed 's/<text_to_replace>/<replacement_text>/' <file_name>
```

Давайте попробуем заменить каждое вхождение "1" в файле на "3" с помощью
команды `sed`.

![](images/linux/commands/image31.png)

Содержимое файла не изменится в приведенном выше
примере. Чтобы сделать это, мы должны использовать дополнительный аргумент `-i`, чтобы
изменения отразились в файле.

### sort

Команда `sort` может использоваться для сортировки ввода, предоставленного ей в качестве
аргумента. По умолчанию она будет сортировать в порядке возрастания.

Давайте сначала посмотрим содержимое файла перед попыткой его сортировки.

![](images/linux/commands/image27.png)

Теперь мы попробуем отсортировать файл с помощью команды `sort`. Команда `sort`
сортирует содержимое в лексикографическом порядке.

![](images/linux/commands/image32.png)

Содержимое файла не изменится в приведенном выше
примере.

## Перенаправление ввода-вывода

Каждому открытому файлу присваивается дескриптор файла. Дескриптор файла - это
уникальный идентификатор для открытых файлов в системе. Всегда есть
три файла по умолчанию, которые открыты, `stdin` (клавиатура), `stdout` (экран) и
`stderr` (сообщения об ошибках, выводимые на экран). Эти файлы могут быть
перенаправлены.

Все в Linux - это файл -
[https://unix.stackexchange.com/questions/225537/everything-is-a-file](https://unix.stackexchange.com/questions/225537/everything-is-a-file)

До сих пор мы отображали весь вывод на экране, который является
стандартным выводом. Мы можем использовать некоторые специальные операторы для перенаправления
вывода команды в файлы или даже на ввод других команд.
Перенаправление ввода-вывода - очень мощная функция.

В приведенном ниже примере мы использовали оператор `>` для перенаправления
вывода команды `ls` в файл `output.txt`.

![](images/linux/commands/image30.png)

В приведенном ниже примере мы перенаправили вывод из команды `echo` в
файл.

![](images/linux/commands/image13.png)

Мы также можем перенаправить вывод команды в качестве ввода для другой
команды. Это возможно с помощью каналов.

В приведенном ниже примере мы передали вывод команды `cat` в качестве
ввода для команды `grep` с помощью оператора канала (`|`).

![](images/linux/commands/image6.png)

В приведенном ниже примере мы передали вывод команды `sort` в качестве
ввода для команды `uniq` с помощью оператора канала (`|`). Команда `uniq`
выводит только уникальные числа из ввода.

![](images/linux/commands/image28.png)

Перенаправление ввода-вывода -
[https://tldp.org/LDP/abs/html/io-redirection.html](https://tldp.org/LDP/abs/html/io-redirection.html)

# Git с GitHub

До сих пор все операции, которые мы выполняли, были в нашем локальном репозитории, в то время как git также помогает в совместной работе. GitHub - это одно из мест в Интернете, где вы можете централизованно размещать свои репозитории git и сотрудничать с другими разработчиками.

Большая часть рабочего процесса останется такой же, как мы обсуждали, с добавлением пары вещей:

 1. Pull: для получения последних изменений из репозитория GitHub (центрального)
 2. Push: для отправки ваших изменений в репозиторий GitHub, чтобы они были доступны всем людям

GitHub написал хорошие руководства и учебники об этом, и вы можете обратиться к ним здесь:

- [GitHub Hello World](https://guides.github.com/activities/hello-world/)
- [Git Handbook](https://guides.github.com/introduction/git-handbook/)

## Хуки

Git имеет еще одну хорошую функцию, называемую хуками. Хуки - это, по сути, скрипты, которые будут вызываться при наступлении определенного события. Вот где находятся хуки:

```bash
$ ls .git/hooks/
applypatch-msg.sample     fsmonitor-watchman.sample pre-applypatch.sample     pre-push.sample           pre-receive.sample        update.sample
commit-msg.sample         post-update.sample        pre-commit.sample         pre-rebase.sample         prepare-commit-msg.sample
```

Названия говорят сами за себя. Эти хуки полезны, когда вы хотите выполнить определенные действия при наступлении определенного события. Если вы хотите запустить тесты перед отправкой кода, вы можете настроить хуки `pre-push`. Давайте попробуем создать хук pre-commit.

```bash
$ echo "echo this is from pre commit hook" > .git/hooks/pre-commit
$ chmod +x .git/hooks/pre-commit
```

Мы, по сути, создаем файл с именем `pre-commit` в папке hooks и делаем его исполняемым. Теперь, если мы сделаем коммит, мы должны увидеть сообщение, которое печатается.

```bash
$ echo "sample file" > sample.txt
$ git add sample.txt
$ git commit -m "adding sample file"
this is from pre commit hook     # <===== СООБЩЕНИЕ ОТ ВЫПОЛНЕНИЯ ХУКА
[master 9894e05] adding sample file
1 file changed, 1 insertion(+)
create mode 100644 sample.txt
```

# Архитектура MySQL

![alt_text](images/mysql_architecture.png "Диаграмма архитектуры MySQL")

Архитектура MySQL позволяет выбрать правильный движок хранения для ваших нужд и абстрагирует все детали реализации от конечных пользователей (инженеров приложений и [DBA](https://en.wikipedia.org/wiki/Database_administrator)), которым нужно знать только стабильный и последовательный API.

Уровень приложения:

*   Обработка соединений: каждый клиент получает свое собственное соединение, которое кэшируется на время доступа
*   Аутентификация: сервер проверяет информацию (имя пользователя, пароль, хост) клиента и разрешает/отклоняет соединение
*   Безопасность: сервер определяет, имеет ли клиент привилегии для выполнения каждого запроса (проверьте с помощью команды `SHOW PRIVILEGES`)

Уровень сервера:

*   Сервисы и утилиты: резервное копирование/восстановление, репликация, кластер и т.д.
*   Интерфейс SQL: клиенты выполняют запросы для доступа к данным и манипулирования ими
*   Парсер SQL: создает дерево разбора из запроса (лексический/синтаксический/семантический анализ и генерация кода)
*   Оптимизатор: оптимизирует запросы, используя различные алгоритмы и доступные данные (статистика на уровне таблиц), изменяет запросы, порядок сканирования, используемые индексы и т.д. (проверьте с помощью команды `EXPLAIN`)
*   Кэши и буферы: кэш хранит результаты запросов, пул буферов (InnoDB) хранит данные таблиц и индексов в [LRU](https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)) манере

Варианты движков хранения:

*   InnoDB: наиболее широко используемый, поддержка транзакций, соответствие ACID, поддерживает блокировку на уровне строк, восстановление после сбоев и многоверсионный контроль параллелизма. По умолчанию с MySQL 5.5+.
*   MyISAM: быстрый, не поддерживает транзакции, обеспечивает блокировку на уровне таблиц, отлично подходит для рабочих нагрузок с преобладанием чтения, в основном в веб и хранилищах данных. По умолчанию до MySQL 5.1.
*   Archive: оптимизирован для высокоскоростных вставок, сжимает данные при их вставке, не поддерживает транзакции, идеально подходит для хранения и извлечения больших объемов редко используемых исторических, архивных данных
*   Memory: таблицы в памяти. Самый быстрый движок, поддерживает блокировку на уровне таблиц, не поддерживает транзакции, идеально подходит для создания временных таблиц или быстрых поисков, данные теряются после выключения
*   CSV: хранит данные в файлах CSV, отлично подходит для интеграции с другими приложениями, использующими этот формат
*   … и т.д.

Возможно мигрировать с одного движка хранения на другой. Но эта миграция блокирует таблицы для всех операций и не является онлайн, так как изменяет физическую компоновку данных. Это занимает много времени и обычно не рекомендуется. Следовательно, выбор правильного движка хранения в начале важен.

Общее руководство - использовать InnoDB, если у вас нет конкретной потребности в одном из других движков хранения.

Запуск `mysql> SHOW ENGINES;` показывает поддерживаемые движки на вашем сервере MySQL.

# Заключение

Мы рассмотрели основные концепции Служб Сообщений. Есть еще много чему учиться и делать. Мы надеемся, что этот курс дает вам хороший старт и вдохновляет вас на дальнейшее изучение.

# Дополнительное чтение

[https://sudhir.io/the-big-little-guide-to-message-queues](https://sudhir.io/the-big-little-guide-to-message-queues)

[Understanding message brokers: learn the mechanics of messaging though ActiveMQ and Kafka](http://www.oreilly.com/programming/free/understanding-message-brokers.csp)

[Видео: The Myth of the Magical Messaging Fabric by Jakub Korab](https://www.youtube.com/watch?v=Ie3--CSpCGs)

[G. Fu, Y. Zhang and G. Yu, "A Fair Comparison of Message Queuing Systems," in IEEE Access, vol. 9, pp. 421-432, 2021, doi: 10.1109/ACCESS.2020.3046503.](https://ieeexplore.ieee.org/document/9303425) ([PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9303425))

[Design Patterns for Cloud Native Applications: Chapter 2 Communication Patterns]()

[Choose between Azure messaging services - Event Grid, Event Hubs, and Service Bus](https://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services)

[Exactly-once message delivery](https://exactly-once.github.io/posts/exactly-once-delivery/)

[Task Queues](https://taskqueues.com/)

[RabbitMQ tutorial](https://www.rabbitmq.com/getstarted.html)

##

# Предварительные требования

-   [Основы Linux](https://linkedin.github.io/school-of-sre/level101/linux_basics/intro/)

-   [Python и Веб](https://linkedin.github.io/school-of-sre/level101/python_web/intro/)

-   [Проектирование систем](https://linkedin.github.io/school-of-sre/level101/systems_design/intro/)

-   [Основы сетей Linux](https://linkedin.github.io/school-of-sre/level101/linux_networking/intro/)


## Чего ожидать от этого курса

Мониторинг является неотъемлемой частью любой системы. Как SRE, вам необходимо
иметь базовое понимание мониторинга инфраструктуры сервиса. К
концу этого курса вы получите лучшее понимание следующих
тем:

-   Что такое мониторинг?

    -   Что нужно измерять

    -   Как собранные метрики могут быть использованы для улучшения бизнес-решений и общей надежности

    -   Проактивный мониторинг с оповещениями

    -   Обработка логов и ее важность

-   Что такое наблюдаемость?

    -   Распределенная трассировка

    -   Логи

    -   Метрики

## Что не охвачено в этом курсе

-   Руководство по настройке инфраструктуры мониторинга

-   Глубокое погружение в различные технологии мониторинга и сравнительный анализ или сравнение любых инструментов


## Содержание курса

-   [Введение](https://linkedin.github.io/school-of-sre/level101/metrics_and_monitoring/introduction/#introduction)

    -   [Четыре золотых сигнала мониторинга](https://linkedin.github.io/school-of-sre/level101/metrics_and_monitoring/introduction/#four-golden-signals-of-monitoring)

    -   [Почему мониторинг важен?](https://linkedin.github.io/school-of-sre/level101/metrics_and_monitoring/introduction/#why-is-monitoring-important)

-   [Инструменты командной строки](https://linkedin.github.io/school-of-sre/level101/metrics_and_monitoring/command-line_tools/)

-   [Мониторинг третьих сторон](https://linkedin.github.io/school-of-sre/level101/metrics_and_monitoring/third-party_monitoring/)

-   [Проактивный мониторинг с использованием оповещений](https://linkedin.github.io/school-of-sre/level101/metrics_and_monitoring/alerts/)

-   [Лучшие практики для мониторинга](https://linkedin.github.io/school-of-sre/level101/metrics_and_monitoring/best_practices/)

-   [Наблюдаемость](https://linkedin.github.io/school-of-sre/level101/metrics_and_monitoring/observability/)

    -   [Логи](https://linkedin.github.io/school-of-sre/level101/metrics_and_monitoring/observability/#logs)
    -   [Трассировка](https://linkedin.github.io/school-of-sre/level101/metrics_and_monitoring/bservability/#tracing)

[Заключение](https://linkedin.github.io/school-of-sre/level101/metrics_and_monitoring/conclusion/)


##

# Введение

Мониторинг - это процесс сбора метрик производительности в реальном времени из
системы, анализа данных для получения значимой информации и
отображения данных для пользователей. Простыми словами, вы измеряете различные
метрики регулярно, чтобы понять состояние системы, включая, но не
ограничиваясь, запросы пользователей, задержку и частоту ошибок. *Что
измеряется, то исправляется*&mdash;если вы можете что-то измерить, вы можете рассуждать
об этом, понимать это, обсуждать это и действовать с уверенностью.


## Четыре золотых сигнала мониторинга

При настройке мониторинга для системы вам нужно решить, что
измерять. Четыре золотых сигнала мониторинга обеспечивают хорошее
понимание производительности сервиса и закладывают основу для мониторинга
системы. Эти четыре золотых сигнала:

-   Трафик

-   Задержка

-   Ошибка

-   Насыщение

Эти метрики помогают вам понять производительность системы и
узкие места, а также создать лучший опыт для конечных пользователей. Как обсуждалось в
[книге Google SRE](https://sre.google/sre-book/monitoring-distributed-systems/),
если вы можете измерить только четыре метрики вашего сервиса, сосредоточьтесь на этих
четырех. Давайте рассмотрим каждый из четырех золотых сигналов.

-   **Трафик**&mdash;*Трафик* дает лучшее понимание спроса на сервис. Часто называемый *QPS сервиса* (запросы в секунду),
     трафик - это мера запросов, обслуживаемых сервисом. Этот
     сигнал помогает вам решить, когда сервис нужно масштабировать для
     обработки увеличивающегося спроса клиентов и масштабировать вниз для
     экономической эффективности.

-   **Задержка**&mdash;*Задержка* - это мера времени, затрачиваемого сервисом
     на обработку входящего запроса и отправку ответа. Измерение
     задержки сервиса помогает в раннем обнаружении медленной деградации
     сервиса. Важно различать задержку успешных
     запросов и задержку неудачных запросов. Например, [ошибка HTTP 5XX](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#server_error_responses)
     вызванная из-за потери соединения с базой данных или другим
     критическим бэкендом, может быть обслужена очень быстро. Однако, поскольку ошибка HTTP 500 указывает на неудачный запрос, учет 500 в
     общей задержке может привести к вводящим в заблуждение расчетам.

-   **Ошибка (частота)**&mdash;*Ошибка* - это мера неудачных запросов клиентов. Эти сбои можно легко идентифицировать на основе
     кодов ответа ([ошибка HTTP 5XX](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#server_error_responses)). Могут быть случаи, когда ответ считается ошибочным
     из-за неправильных данных результата или из-за нарушений политики. Например,
     вы можете получить ответ [HTTP 200](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200), но тело имеет неполные данные, или время ответа
     нарушает согласованные [SLA](https://en.wikipedia.org/wiki/Service-level_agreement). Поэтому вам нужно иметь другие механизмы (логика кода или
     [инструментация](https://en.wikipedia.org/wiki/Instrumentation_(computer_programming)))
     для захвата ошибок в дополнение к кодам ответа.

-   **Насыщение**&mdash;*Насыщение* - это мера использования ресурсов
     сервисом. Этот сигнал сообщает о состоянии ресурсов сервиса и насколько они заполнены. Эти ресурсы включают
     память, вычисления, сетевой ввод-вывод и так далее. Производительность сервиса
     медленно деградирует даже до того, как использование ресурсов достигнет 100
     процентов. Поэтому важно иметь целевое использование. Увеличение задержки - хороший индикатор насыщения; измерение [99-го процентиля](https://medium.com/@ankur_anand/an-in-depth-introduction-to-99-percentile-for-programmers-22e83a00caf)
     задержки может помочь в раннем обнаружении насыщения.

В зависимости от типа сервиса вы можете измерять эти сигналы по-разному. Например, вы можете измерять запросы в секунду, обслуживаемые
для веб-сервера. В отличие от этого, для сервера базы данных выполненные транзакции и созданные сеансы базы данных дают вам представление о трафике, обрабатываемом сервером базы данных. С помощью дополнительной логики кода (библиотеки мониторинга и инструментация) вы можете периодически измерять эти
сигналы и хранить их для будущего анализа. Хотя эти
метрики дают вам представление о производительности на стороне сервиса, вам
также нужно убедиться, что тот же пользовательский опыт доставляется на
стороне клиента. Поэтому вам может потребоваться мониторить сервис извне
инфраструктуры сервиса, что обсуждается в разделе мониторинга третьих сторон.

## Почему мониторинг важен?

Мониторинг играет ключевую роль в успехе сервиса. Как обсуждалось
ранее, мониторинг предоставляет информацию о производительности для понимания
здоровья сервиса. С доступом к историческим данным, собранным с течением времени, вы
можете создавать интеллектуальные приложения для удовлетворения конкретных потребностей. Некоторые из
ключевых случаев использования:

-   **Сокращение времени на решение проблем**&mdash;С хорошей инфраструктурой мониторинга вы можете быстро идентифицировать проблемы и
     решить их, что снижает воздействие, вызванное проблемами.

-   **Бизнес-решения**&mdash;Данные, собранные за период времени, могут
     помочь вам принимать бизнес-решения, такие как определение цикла
     выпуска продукта, в какие функции инвестировать и на какие географические области
     сосредоточиться. Решения, основанные на долгосрочных данных, могут улучшить
     общий опыт продукта.

-   **Планирование ресурсов**&mdash;Анализируя исторические данные, вы можете
     прогнозировать потребности сервиса в вычислительных ресурсах и можете правильно
     распределять ресурсы. Это позволяет принимать финансово эффективные решения,
     без компромисса в опыте конечного пользователя.

Прежде чем мы углубимся в мониторинг, давайте поймем некоторые основные
терминологии.

-   **Метрика**&mdash;Метрика - это количественная мера конкретного
     атрибута системы&mdash;например, память или ЦП

-   **Узел или хост**&mdash;Физический сервер, виртуальная машина или контейнер,
     где работает приложение

-   **QPS**&mdash;*Запросы в секунду*, мера трафика, обслуживаемого
     сервисом в секунду

-   **Задержка**&mdash;Временной интервал между действием пользователя и
     ответом от сервера&mdash;например, время, затраченное после отправки
     запроса к базе данных до получения первого бита ответа

-   **Частота ошибок**&mdash;Количество ошибок, наблюдаемых за определенный
     период времени (обычно секунду)

-   **График**&mdash;В мониторинге график - это представление одного или
     нескольких значений метрик, собранных с течением времени

-   **Панель**&mdash;Панель - это коллекция графиков, которые предоставляют
     обзор здоровья системы

-   **Инцидент**&mdash;Инцидент - это событие, которое нарушает нормальные
     операции системы

-   **MTTD**&mdash;*Среднее время до обнаружения* - это временной интервал между
     началом сбоя сервиса и обнаружением такого сбоя

-   **MTTR**&mdash;Среднее время до решения - это время, затраченное на исправление сбоя сервиса
     и возвращение сервиса в нормальное состояние

Прежде чем мы обсудим мониторинг приложения, давайте посмотрим на
инфраструктуру мониторинга. Ниже приведена иллюстрация базовой
системы мониторинга.

![Иллюстрация инфраструктуры мониторинга](images/image1.jpg) 
<p align="center"> Рисунок 1: Иллюстрация инфраструктуры мониторинга </p>

Рисунок 1 показывает механизм инфраструктуры мониторинга для агрегирования
метрик в системе, сбора и хранения данных для отображения. Кроме того, инфраструктура мониторинга включает подсистемы оповещения для
уведомления заинтересованных сторон при любом аномальном поведении. Давайте рассмотрим каждый из этих компонентов инфраструктуры:

-   **Агент метрик хоста**&mdash;*Агент метрик хоста* - это процесс,
     работающий на хосте, который собирает статистику производительности для подсистем хоста,
     таких как память, ЦП и сеть. Эти метрики регулярно передаются
     сборщику метрик для хранения и визуализации. Некоторые примеры:
     [collectd](https://collectd.org/),
     [telegraf](https://www.influxdata.com/time-series-platform/telegraf/),
     и [metricbeat](https://www.elastic.co/beats/metricbeat).

-   **Агрегатор метрик**&mdash;*Агрегатор метрик* - это процесс, работающий
     на хосте. Приложения, работающие на хосте, собирают метрики сервиса
     с помощью [инструментации](https://en.wikipedia.org/wiki/Instrumentation_(computer_programming)).
     Собранные метрики отправляются либо в процесс агрегатора, либо
     непосредственно сборщику метрик через API, если доступно. Полученные
     метрики периодически агрегируются и передаются
     сборщику метрик пакетами. Пример:
     [StatsD](https://github.com/statsd/statsd).

-   **Сборщик метрик**&mdash;Процесс *сборщика метрик* собирает все
     метрики от агрегаторов метрик, работающих на нескольких хостах.
     Сборщик заботится о декодировании и хранит эти данные в
     базе данных. Сбор метрик и хранение могут быть обработаны
     одним сервисом, таким как
     [InfluxDB](https://www.influxdata.com/), который мы обсудим
     далее. Пример: [carbon
     daemons](https://graphite.readthedocs.io/en/latest/carbon-daemons.html).

-   **Хранилище**&mdash;База данных временных рядов хранит все эти метрики.
     Примеры: [OpenTSDB](http://opentsdb.net/),
     [Whisper](https://graphite.readthedocs.io/en/stable/whisper.html),
     и [InfluxDB](https://www.influxdata.com/).

-   **Сервер метрик**&mdash;*Сервер метрик* может быть таким же базовым, как веб-сервер,
     который графически отображает данные метрик. Кроме того, сервер метрик предоставляет функциональность агрегации и API для
     программного получения данных метрик. Некоторые примеры:
     [Grafana](https://github.com/grafana/grafana) и
     [Graphite-Web](https://github.com/graphite-project/graphite-web).

-   **Менеджер оповещений**&mdash;*Менеджер оповещений* регулярно опрашивает данные метрик
     и, если обнаружены какие-либо аномалии, уведомляет вас. У каждого оповещения есть набор правил для идентификации таких аномалий.
     Сегодня многие серверы метрик, такие как
     [Grafana](https://github.com/grafana/grafana), поддерживают управление
     оповещениями. Мы обсудим оповещения [подробно
     позже](https://linkedin.github.io/school-of-sre/level101/metrics_and_monitoring/alerts/). Примеры:
     [Grafana](https://github.com/grafana/grafana) и
     [Icinga](https://icinga.com/).

# Некоторые концепции Python

Хотя ожидается, что вы знаете python и его синтаксис на базовом уровне, давайте обсудим некоторые фундаментальные концепции, которые помогут вам лучше понять язык Python.

**Все в Python - это объект.**

Это включает функции, списки, словари, классы, модули, запущенную функцию (экземпляр определения функции), все. В CPython это означало бы, что для каждого объекта есть базовая переменная `struct`.

В текущем контексте выполнения Python все переменные хранятся в словаре. Это было бы отображение строки на объект. Если у вас есть определенная функция и переменная с плавающей точкой, определенная в текущем контексте, вот как это обрабатывается внутренне.

```python
>>> float_number=42.0
>>> def foo_func():
...     pass
...

# ОБРАТИТЕ ВНИМАНИЕ, КАК ИМЕНА ПЕРЕМЕННЫХ ЯВЛЯЮТСЯ СТРОКАМИ, хранящимися в словаре
>>> locals()
{'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, 'float_number': 42.0, 'foo_func': <function foo_func at 0x1055847a0>}
```

## Функции Python

Поскольку функции тоже являются объектами, мы можем увидеть, какие атрибуты содержит функция, следующим образом

```python
>>> def hello(name):
...     print(f"Hello, {name}!")
...
>>> dir(hello)
['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__',
'__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__',
'__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__',
'__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__',
'__subclasshook__']
```

Хотя их много, давайте рассмотрим некоторые интересные.

#### __globals__

Этот атрибут, как следует из названия, имеет ссылки на глобальные переменные. Если вам когда-нибудь нужно узнать, какие глобальные переменные находятся в области видимости этой функции, это вам скажет. Посмотрите, как функция начинает видеть новую переменную в globals

```python
>>> hello.__globals__
{'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, 'hello': <function hello at 0x7fe4e82554c0>}

# добавление новой глобальной переменной
>>> GLOBAL="g_val"
>>> hello.__globals__
{'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': None, '__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, 'hello': <function hello at 0x7fe4e82554c0>, 'GLOBAL': 'g_val'}
```

### __code__

Это интересный! Поскольку все в Python - это объект, это включает и байткод. Скомпилированный байткод Python - это объект Python code. Который доступен через атрибут `__code__` здесь. Функция имеет связанный объект кода, который несет некоторую интересную информацию.

```python
# файл, в котором определена функция
# stdin здесь, поскольку это запущено в интерпретаторе
>>> hello.__code__.co_filename
'<stdin>'

# количество аргументов, которые принимает функция
>>> hello.__code__.co_argcount
1

# имена локальных переменных
>>> hello.__code__.co_varnames
('name',)

# скомпилированный байткод кода функции
>>> hello.__code__.co_code
b't\x00d\x01|\x00\x9b\x00d\x02\x9d\x03\x83\x01\x01\x00d\x00S\x00'
```

Есть больше атрибутов кода, которые вы можете перечислить с помощью `>>> dir(hello.__code__)`.

## Декораторы

Связанные с функциями, Python имеет еще одну функцию, называемую декораторами. Давайте посмотрим, как это работает, имея в виду, что `все является объектом`.

Вот пример декоратора:

```python
>>> def deco(func):
...     def inner():
...             print("before")
...             func()
...             print("after")
...     return inner
...
>>> @deco
... def hello_world():
...     print("hello world")
...
>>>
>>> hello_world()
before
hello world
after
```

Здесь синтаксис `@deco` используется для декорирования функции `hello_world`. По сути, это то же самое, что и

```python
>>> def hello_world():
...     print("hello world")
...
>>> hello_world = deco(hello_world)
```

То, что происходит внутри функции `deco`, может показаться сложным. Давайте попробуем разобраться.

1. Функция `hello_world` создается
2. Она передается функции `deco`
3. `deco` создает новую функцию
      1. Эта новая функция вызывает функцию `hello_world`
      2. И делает пару других вещей
4. `deco` возвращает вновь созданную функцию
5. `hello_world` заменяется вышеуказанной функцией

Давайте визуализируем это для лучшего понимания

```
       ДО                        объект_функции (ID: 100)

       "hello_world"            +--------------------+
               +                |print("hello_world")|
               |                |                    |
               +--------------> |                    |
                                |                    |
                                +--------------------+


       ЧТО ДЕЛАЕТ ДЕКОРАТОР

       создает новую функцию (ID: 101)
       +---------------------------------+
       |входной арг: функция с id: 100   |
       |                                 |
       |print("before")                  |
       |вызов объекта функции с id 100   |
       |print("after")                   |
       |                                 |
       +---------------------------------+
                                   ^
                                   |
       ПОСЛЕ                       |
                                   |
                                   |
       "hello_world" +-------------+
```

Обратите внимание, как имя `hello_world` указывает на новый объект функции, но этот новый объект функции знает ссылку (ID) исходной функции.

## Некоторые подводные камни

- Хотя очень быстро создавать прототипы в Python и есть тонны доступных библиотек, по мере увеличения сложности кодовой базы ошибки типов становятся более распространенными и с ними становится труднее справляться. (Есть решения для этой проблемы, такие как аннотации типов в Python. Проверьте [mypy](http://mypy-lang.org/).)
- Поскольку Python - это динамически типизированный язык, это означает, что все типы определяются во время выполнения. И это делает Python очень медленным по сравнению с другими статически типизированными языками.
- Python имеет что-то, называемое [GIL](https://www.dabeaz.com/python/UnderstandingGIL.pdf) (глобальная блокировка интерпретатора), которая является ограничивающим фактором для использования нескольких ядер ЦП для параллельных вычислений.
- Некоторые странные вещи, которые делает Python: [https://github.com/satwikkansal/wtfpython](https://github.com/satwikkansal/wtfpython).

# Python и Веб

В старые времена веб-сайты были простыми. Они были простым статическим html-содержимым. Веб-сервер прослушивал определенный порт и в соответствии с полученным HTTP-запросом читал файлы с диска и возвращал их в ответ. Но с тех пор сложность эволюционировала, и веб-сайты теперь динамичны. В зависимости от запроса необходимо выполнить несколько операций, таких как чтение из базы данных или вызов другого API, и, наконец, возвращение некоторого ответа (данные HTML, содержимое JSON и т.д.)

Поскольку обслуживание веб-запросов больше не является простой задачей, такой как чтение файлов с диска и возврат содержимого, нам нужно обрабатывать каждый HTTP-запрос, выполнять некоторые операции программно и конструировать ответ.

## Сокеты

Хотя у нас есть фреймворки, такие как Flask, HTTP все еще является протоколом, который работает поверх протокола TCP. Итак, давайте настроим TCP-сервер и отправим HTTP-запрос и проверим полезную нагрузку запроса. Обратите внимание, что это не учебник по программированию сокетов, но то, что мы делаем здесь, это проверка протокола HTTP на его базовом уровне и просмотр того, как выглядит его содержимое. (Ссылка: [Socket Programming in Python (Guide) on RealPython](https://realpython.com/python-sockets/))

```python
import socket

HOST = '127.0.0.1'  # Стандартный адрес интерфейса обратной связи (localhost)
PORT = 65432        # Порт для прослушивания (непривилегированные порты > 1023)

with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
   s.bind((HOST, PORT))
   s.listen()
   conn, addr = s.accept()
   with conn:
       print('Connected by', addr)
       while True:
           data = conn.recv(1024)
           if not data:
               break
           print(data)
```

Затем мы открываем `localhost:65432` в нашем веб-браузере, и вывод будет следующим:

```bash
Connected by ('127.0.0.1', 54719)
b'GET / HTTP/1.1\r\nHost: localhost:65432\r\nConnection: keep-alive\r\nDNT: 1\r\nUpgrade-Insecure-Requests: 1\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36 Edg/85.0.564.44\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\r\nSec-Fetch-Site: none\r\nSec-Fetch-Mode: navigate\r\nSec-Fetch-User: ?1\r\nSec-Fetch-Dest: document\r\nAccept-Encoding: gzip, deflate, br\r\nAccept-Language: en-US,en;q=0.9\r\n\r\n'
```

Внимательно изучите, и содержимое будет выглядеть как формат протокола HTTP. т.е.:

```
HTTP_METHOD URI_PATH HTTP_VERSION
HEADERS_SEPARATED_BY_SEPARATOR
```

Итак, хотя это блок байтов, зная [спецификацию протокола http](https://tools.ietf.org/html/rfc2616), вы можете разобрать эту строку (т.е.: разделить по `\r\n`) и получить из нее значимую информацию.

## Flask

Flask и другие подобные фреймворки делают примерно то, что мы только что обсудили в последнем разделе (с добавленной большей сложностью). Они прослушивают порт на TCP-сокете, получают HTTP-запрос, разбирают данные в соответствии с форматом протокола и делают их доступными для вас удобным способом.

То есть вы можете получить доступ к заголовкам во Flask через `request.headers`, которые становятся доступными для вас путем разделения вышеуказанной полезной нагрузки по `/r/n`, как определено в протоколе HTTP.

Другой пример: мы регистрируем маршруты во Flask с помощью `@app.route("/hello")`. То, что будет делать Flask, это поддерживать внутренний реестр, который будет сопоставлять `/hello` с функцией, которую вы декорировали. Теперь, когда приходит запрос с маршрутом `/hello` (второй компонент в первой строке, разделенный пробелом), Flask вызывает зарегистрированную функцию и возвращает то, что вернула функция.

То же самое и со всеми другими веб-фреймворками на других языках. Они все работают по схожим принципам. То, что они в основном делают, это понимают протокол HTTP, разбирают данные HTTP-запроса и дают нам, программистам, хороший интерфейс для работы с HTTP-запросами.

Не так уж много магии в этом?

# Приложение для сокращения URL

Давайте создадим очень простое приложение для сокращения URL с использованием Flask и попытаемся включить все аспекты процесса разработки, включая аспекты надежности. Мы не будем создавать пользовательский интерфейс и придумаем минимальный набор API, которого будет достаточно для функционирования приложения.

## Дизайн

Мы не переходим сразу к кодированию. Первое, что мы делаем, это собираем требования. Придумываем подход. Получаем обзор подхода/дизайна от коллег. Развиваем, итерируем, документируем решения и компромиссы. И только потом реализуем. Хотя мы не будем делать полный дизайн-документ здесь, мы поднимем определенные вопросы, которые важны для дизайна.

### 1. Операции высокого уровня и конечные точки API

Поскольку это приложение для сокращения URL, нам понадобится API для генерации сокращенной ссылки для данной оригинальной ссылки. И API/конечная точка, которая будет принимать сокращенную ссылку и перенаправлять на оригинальный URL. Мы не включаем аспект пользователя в приложение, чтобы сохранить его минимальным. Эти два API должны сделать приложение функциональным и пригодным для использования кем угодно.

### 2. Как сокращать?

Учитывая URL, нам нужно будет сгенерировать его сокращенную версию. Один подход мог бы заключаться в использовании случайных символов для каждой ссылки. Другое, что можно сделать, это использовать какой-то алгоритм хеширования. Преимущество здесь в том, что мы будем повторно использовать один и тот же хеш для одной и той же ссылки. То есть, если много людей сокращают `https://www.linkedin.com`, у всех будет одно и то же значение, по сравнению с несколькими записями в БД, если выбраны случайные символы.

Что насчет коллизий хешей? Даже в подходе со случайными символами, хотя вероятность меньше, коллизии хешей могут произойти. И нам нужно быть внимательными к ним. В этом случае мы можем добавить в начало/конец строки некоторое случайное значение, чтобы избежать конфликта.

Также выбор алгоритма хеширования имеет значение. Нам нужно будет проанализировать алгоритмы. Их требования к ЦП и их характеристики. Выбрать тот, который подходит больше всего.

### 3. Валиден ли URL?

Учитывая URL для сокращения, как мы проверяем, валиден ли URL? Проверяем ли мы вообще или валидируем? Одна базовая проверка, которую можно сделать, это посмотреть, соответствует ли URL регулярному выражению URL. Чтобы пойти еще дальше, мы можем попытаться открыть/посетить URL. Но здесь есть определенные подводные камни.

1. Нам нужно определить критерии успеха. т.е.: HTTP 200 означает, что он валиден.
2. Что, если URL находится в частной сети?
3. Что, если URL временно недоступен?

### 4. Хранение

Наконец, хранение. Где мы будем хранить данные, которые мы будем генерировать со временем? Существует множество решений баз данных, и нам нужно будет выбрать то, которое больше всего подходит для этого приложения. Реляционная база данных, такая как MySQL, была бы справедливым выбором, но **обязательно ознакомьтесь с разделом [SQL базы данных](../databases_sql/intro.md) и разделом [NoSQL базы данных](../databases_nosql/intro.md) Школы SRE для более глубокого понимания и принятия более обоснованного решения.**

### 5. Другое

Мы не учитываем пользователей в нашем приложении и другие возможные функции, такие как ограничение скорости, настраиваемые ссылки и т.д., но они в конечном итоге могут появиться со временем. В зависимости от требований, они тоже могут быть включены.

Минимальный рабочий код приведен ниже для справки, но я бы рекомендовал вам придумать свой собственный.

```python
from flask import Flask, redirect, request
from hashlib import md5

app = Flask("url_shortener")

mapping = {}

@app.route("/shorten", methods=["POST"])
def shorten():
    global mapping
    payload = request.json

    if "url" not in payload:
        return "Missing URL Parameter", 400

    # TODO: проверить, валиден ли URL

    hash_ = md5()
    hash_.update(payload["url"].encode())
    digest = hash_.hexdigest()[:5]  # ограничение до 5 символов. Чем меньше лимит, тем больше шансов коллизии

    if digest not in mapping:
        mapping[digest] = payload["url"]
        return f"Shortened: r/{digest}\n"
    else:
        # TODO: проверить на коллизию хеша
        return f"Already exists: r/{digest}\n"


@app.route("/r/<hash_>")
def redirect_(hash_):
    if hash_ not in mapping:
        return "URL Not Found", 404
    return redirect(mapping[hash_])


if __name__ == "__main__":
    app.run(debug=True)

"""
ВЫВОД:


===> СОКРАЩЕНИЕ

$ curl localhost:5000/shorten -H "content-type: application/json" --data '{"url":"https://linkedin.com"}'
Shortened: r/a62a4


===> ПЕРЕНАПРАВЛЕНИЕ, обратите внимание на код ответа 302 и заголовок location

$ curl localhost:5000/r/a62a4 -v
* Uses proxy env variable NO_PROXY == '127.0.0.1'
*   Trying ::1...
* TCP_NODELAY set
* Connection failed
* connect to ::1 port 5000 failed: Connection refused
*   Trying 127.0.0.1...
* TCP_NODELAY set
* Connected to localhost (127.0.0.1) port 5000 (#0)
> GET /r/a62a4 HTTP/1.1
> Host: localhost:5000
> User-Agent: curl/7.64.1
> Accept: */*
>
* HTTP 1.0, assume close after body
< HTTP/1.0 302 FOUND
< Content-Type: text/html; charset=utf-8
< Content-Length: 247
< Location: https://linkedin.com
< Server: Werkzeug/0.15.4 Python/3.7.7
< Date: Tue, 27 Oct 2020 09:37:12 GMT
<
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<title>Redirecting...</title>
<h1>Redirecting...</h1>
* Closing connection 0
<p>You should be redirected automatically to target URL: <a href="https://linkedin.com">https://linkedin.com</a>.  If not click the link.
"""
```

# Заключение

Мы рассмотрели основные концепции баз данных SQL. Мы также рассмотрели некоторые задачи, за которые может отвечать SRE&mdash;есть еще так много чему учиться и делать. Мы надеемся, что этот курс даст вам хороший старт и вдохновит вас на дальнейшее изучение.


### Дополнительное чтение

*   Больше практики с онлайн-ресурсами, такими как [этот](https://www.w3resource.com/sql-exercises/index.php)
*   [Нормализация](https://beginnersbook.com/2015/05/normalization-in-dbms/)
*   [Процедуры](https://dev.mysql.com/doc/refman/8.0/en/stored-routines.html), [триггеры](https://dev.mysql.com/doc/refman/8.0/en/trigger-syntax.html)
*   [Представления](https://www.essentialsql.com/what-is-a-relational-database-view/)
*   [Уровни изоляции транзакций](https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html)
*   [Шардинг](https://www.digitalocean.com/community/tutorials/understanding-database-sharding)
*   [Настройка HA](https://severalnines.com/database-blog/introduction-database-high-availability-mysql-mariadb), [мониторинг](https://blog.serverdensity.com/how-to-monitor-mysql/), [резервное копирование](https://dev.mysql.com/doc/refman/8.0/en/backup-methods.html)

# Заключение

Надежная система мониторинга и оповещения необходима для поддержания и
устранения неполадок в системе. Панель с ключевыми метриками может дать вам
обзор производительности сервиса, все в одном месте. Хорошо определенные оповещения 
(с реалистичными порогами и уведомлениями) дополнительно позволяют вам
быстро идентифицировать любые аномалии в инфраструктуре сервиса и в
насыщении ресурсов. Принимая необходимые меры, вы можете избежать любых
деградаций сервиса и уменьшить MTTD для сбоев сервиса.

В дополнение к внутреннему мониторингу, мониторинг реального опыта пользователей может
помочь вам понять производительность сервиса, как ее воспринимают пользователи.
Многие модули участвуют в обслуживании пользователя, и большинство из них находятся
вне вашего контроля. Поэтому вам нужно иметь мониторинг реальных пользователей на
месте.

Метрики дают очень абстрактные детали о производительности сервиса. Чтобы получить
лучшее понимание системы и для более быстрого восстановления во время
инцидентов, вы можете захотеть реализовать два других столпа
наблюдаемости: логи и трассировку. Логи и данные трассировки могут помочь вам
понять, что привело к сбою или деградации сервиса.

Ниже приведены некоторые ресурсы для изучения большего о мониторинге и
наблюдаемости:

-   [Книга Google SRE: Мониторинг распределенных
     систем](https://sre.google/sre-book/monitoring-distributed-systems/)

-   [Mastering Distributed Tracing by Yuri
     Shkuro](https://learning.oreilly.com/library/view/mastering-distributed-tracing/9781788628464/)


## Ссылки

-   [Книга Google SRE: Мониторинг распределенных
     систем](https://sre.google/sre-book/monitoring-distributed-systems/)

-   [Mastering Distributed Tracing, by Yuri
     Shkuro](https://learning.oreilly.com/library/view/mastering-distributed-tracing/9781788628464/)

-   [Мониторинг и
     наблюдаемость](https://copyconstruct.medium.com/monitoring-and-observability-8417d1952e1c)

-   [Три столпа с нулевыми
     ответами](https://medium.com/lightstephq/three-pillars-with-zero-answers-2a98b36358b8)

-   Инженерные блоги на
         [LinkedIn](https://engineering.linkedin.com/blog/topic/monitoring),
         [Grafana](https://grafana.com/blog/),
         [Elastic.co](https://www.elastic.co/blog/),
         [OpenTelemetry](https://medium.com/opentelemetry)

# Задачи и заключение

## Задачи после обучения:

1. Попробуйте настроить свой собственный трехузловой кластер Hadoop. 
    1. Решение на основе VM можно найти [здесь](http://hortonworks.com/wp-content/uploads/2015/04/Import_on_VBox_4_07_2015.pdf)
2. Напишите простую задачу Spark/MR по вашему выбору и поймите, как генерировать аналитику из данных.
    1. Образец набора данных можно найти [здесь](https://grouplens.org/datasets/movielens/)

## Ссылки:
1. [Документация Hadoop](http://hadoop.apache.org/docs/current/)
2. [Архитектура HDFS](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)
3. [Архитектура YARN](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)
4. [Статья Google GFS](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/035fc972c796d33122033a0614bc94cff1527999.pdf)

# Заключение

Теперь, когда вы завершили этот курс по безопасности, вы теперь осведомлены о возможных угрозах безопасности компьютерных систем и сетей. Не только это, но вы теперь лучше способны защитить свои системы, а также рекомендовать меры безопасности другим.

Этот курс предоставляет фундаментальные повседневные знания в области безопасности, которые также помогут вам держать безопасность на вершине ваших приоритетов.

## Другие ресурсы

Некоторые книги, которые были бы отличным ресурсом

- Holistic Info-Sec for Web Developers (<https://holisticinfosecforwebdevelopers.com/>)&mdash;Бесплатная и скачиваемая серия книг с очень широким и глубоким охватом того, что веб-разработчики и инженеры DevOps должны знать, чтобы создавать надежное, надежное, поддерживаемое и безопасное программное обеспечение, сети и другое, которые доставляются непрерывно, вовремя, без неприятных сюрпризов.

- Docker Security: Quick Reference&mdash;For DevOps Engineers (<https://leanpub.com/dockersecurity-quickreference>)&mdash;Книга о понимании настроек безопасности Docker по умолчанию, как их улучшить (теория и практика), вместе со многими инструментами и техниками.

- How to Hack Like a Legend (<https://amzn.to/2uWh1Up>)&mdash;Рассказ хакера о взломе секретной оффшорной компании, Sparc Flow, 2018

- How to Investigate Like a Rockstar (<https://books2read.com/u/4jDWoZ>)&mdash;Переживите настоящий кризис, чтобы освоить секреты судебного анализа, Sparc Flow, 2017

- Real World Cryptography (<https://www.manning.com/books/real-world-cryptography>)&mdash;Эта книга с ранним доступом учит вас прикладным криптографическим техникам для понимания и применения безопасности на всех уровнях ваших систем и приложений.

- AWS Security (<https://www.manning.com/books/aws-security?utm_source=github&utm_medium=organic&utm_campaign=book_shields_aws_1_31_20>)&mdash;Эта книга с ранним доступом охватывает общие проблемы безопасности AWS и лучшие практики для политик доступа, защиты данных, аудита, непрерывного мониторинга и реагирования на инциденты.

## Пост-тренинговые задания/Дополнительное чтение

- События CTF, такие как: <https://github.com/apsdehal/awesome-ctf>
- Тестирование на проникновение: <https://github.com/enaqx/awesome-pentest>
- Разведка угроз: <https://github.com/hslatman/awesome-threat-intelligence>
- Обнаружение и охота за угрозами: <https://github.com/0x4D31/awesome-threat-detection>
- Веб-безопасность: <https://github.com/qazbnm456/awesome-web-security>
- Создание безопасных и надежных систем: <https://landing.google.com/sre/resources/foundationsandprinciples/srs-book/>

# Заключение

Вооружившись этими принципами, мы надеемся, что курс даст свежий взгляд на проектирование программных систем. Может быть чрезмерным инженерным решением получить все это в нулевой день. Но некоторые действительно важны с нулевого дня, такие как устранение единых точек отказа, создание масштабируемых сервисов просто путем увеличения реплик. По мере достижения узкого места мы можем _разделить код по сервисам_, _шардировать данные_ для масштабирования. По мере созревания организации, внедрение [инженерии хаоса](https://en.wikipedia.org/wiki/Chaos_engineering) для измерения того, как системы реагируют на сбои, поможет в проектировании надежных программных систем.

# Обзор больших данных

1. Большие данные - это коллекция больших наборов данных, которые не могут быть обработаны с использованием традиционных вычислительных техник. Это не одна техника или инструмент, скорее это стало полноценным предметом, который включает различные инструменты, техники и фреймворки.
2. Большие данные могут состоять из
    1. Структурированных данных
    2. Неструктурированных данных
    3. Полуструктурированных данных
3. Характеристики больших данных:
    1. Объем
    2. Разнообразие
    3. Скорость
    4. Изменчивость
4. Примеры генерации больших данных включают фондовые биржи, сайты социальных сетей, реактивные двигатели и т.д.


# Использование техник больших данных

1. Возьмем пример проблемы светофоров.
    1. В США более 300 000 светофоров по состоянию на 2018 год.
    2. Предположим, что мы разместили устройство на каждом из них для сбора метрик и отправки их в центральную систему сбора метрик.
    3. Если каждое из устройств IoT отправляет 10 событий в минуту, у нас есть `300000 x 10 x 60 x 24 = 432 x 10 ^ 7` событий в день.
    4. Как бы вы обработали это и сказали мне, сколько сигналов были "зелеными" в 10:45 утра в определенный день?
2. Рассмотрим следующий пример транзакций Unified Payments Interface (UPI):
    1. У нас было около 1,15 миллиарда транзакций UPI в октябре 2019 года в Индии.
    12. Если мы попытаемся экстраполировать эти данные примерно на год и попытаемся найти некоторые общие платежи, которые происходили через определенный UPI ID, как вы предлагаете нам подойти к этому?
